
@article{alexander2015a,
  title = {Beware of {{R2}}: Simple, Unambiguous Assessment of the Prediction Accuracy of {{QSAR}} and {{QSPR}} Models},
  shorttitle = {Beware of {{R2}}},
  author = {Alexander, D. L. J. and Tropsha, A. and Winkler, David A.},
  year = {2015},
  month = jul,
  volume = {55},
  pages = {1316--1322},
  issn = {1549-9596},
  doi = {10.1021/acs.jcim.5b00206},
  abstract = {The statistical metrics used to characterize the external predictivity of a model, i.e., how well it predicts the properties of an independent test set, have proliferated over the past decade. This paper clarifies some apparent confusion over the use of the coefficient of determination, R2, as a measure of model fit and predictive power in QSAR and QSPR modelling., R2 (or R2) has been used in various contexts in the literature in conjunction with training and test data, for both ordinary linear regression and regression through the origin as well as with linear and nonlinear regression models. We analyze the widely adopted model fit criteria suggested by Golbraikh and Tropsha in a strict statistical manner. Shortcomings in these criteria are identified and a clearer and simpler alternative method to characterize model predictivity is provided. The intent is not to repeat the well-documented arguments for model validation using test data, but to guide the application of R2 as a model fit statistic., Examples are used to illustrate both correct and incorrect use of R2. Reporting the root mean squared error or equivalent measures of dispersion, typically of more practical importance than R2, is also encouraged and important challenges in addressing the needs of different categories of users such as computational chemists, experimental scientists, and regulatory decision support specialists are outlined.},
  file = {/Users/pjs/Zotero/storage/ZCN45MGT/Alexander et al. - 2015 - Beware of R2 simple, unambiguous assessment of th.pdf},
  journal = {Journal of chemical information and modeling},
  number = {7},
  pmcid = {PMC4530125},
  pmid = {26099013}
}

@article{anderson2005,
  title = {Scale-{{Dependent Summer Resource Selection}} by {{Reintroduced Elk}} in {{Wisconsin}}, {{USA}}},
  author = {Anderson, P. and Turner, Monica G. and Forester, James D. and Zhu, Jun and Boyce, Mark S. and Beyer, Hawthorne and Stowell, Laine},
  year = {2005},
  volume = {69},
  pages = {298--310},
  publisher = {{[Wiley, Wildlife Society]}},
  issn = {0022-541X},
  abstract = {Identifying how habitat use is influenced by environmental heterogeneity at different scales is central to understanding ungulate population dynamics on complex landscapes. We used resource selection functions (RSF) to study summer habitat use in a reintroduced and expanding elk (Cervus elaphus nelsoni) population in the Chequamegon National Forest, Wisconsin, USA. Factors were examined that influenced where elk established home ranges and that influenced habitat use within established home ranges. We also determined grain sizes over which elk responded to environmental heterogeneity and the number of categories of habitat selection from low to high that the elk distinguished. At a large spatial extent, elk home-range establishment was largely explained by the spatial distribution of wolf (Canis lupus) territories. Forage abundance was also influential but was relatively more important at a small spatial extent when elk moved within established home ranges. Areas near roads were avoided when establishing a home-range, but areas near roads were selected for use within the established home range. Elk distinguished among 4 different categories of habitat selection when establishing and moving within home ranges. Spatial and temporal cross validation demonstrated that to improve the predictive strength of habitat models in areas of low inter-annual variability in the environment, it is better to follow more individuals across diverse environmental conditions than to follow the same individuals over a longer time period. Last, our results show that the effects of environmental variables on habitat use were scale-dependent and reemphasize the necessity of analyzing habitat use at multiple scales that are fit to address specific research questions.},
  journal = {The Journal of Wildlife Management},
  number = {1}
}

@article{arlot2010,
  title = {A Survey of Cross-Validation Procedures for Model Selection},
  author = {Arlot, Sylvain and Celisse, Alain},
  year = {2010},
  month = jan,
  volume = {4},
  pages = {40--79},
  publisher = {{Amer. Statist. Assoc., the Bernoulli Soc., the Inst. Math. Statist., and the Statist. Soc. Canada}},
  issn = {1935-7516},
  doi = {10.1214/09-SS054},
  abstract = {Used to estimate the risk of an estimator or to perform model selection, cross-validation is a widespread strategy because of its simplicity and its (apparent) universality. Many results exist on model selection performances of cross-validation procedures. This survey intends to relate these results to the most recent advances of model selection theory, with a particular emphasis on distinguishing empirical statements from rigorous theoretical results. As a conclusion, guidelines are provided for choosing the best cross-validation procedure according to the particular features of the problem in hand.},
  file = {/Users/pjs/Zotero/storage/5YRIDVDH/Arlot and Celisse - 2010 - A survey of cross-validation procedures for model .pdf;/Users/pjs/Zotero/storage/GIXSIQE2/09-SS054.html},
  journal = {Statistics Surveys},
  keywords = {62G05,62G08,62G09,cross-validation,leave-one-out,Model selection},
  number = {none}
}

@article{bahn2012,
  title = {Testing the Predictive Performance of Distribution Models},
  author = {Bahn, Volker and McGill, Brian J.},
  year = {2012},
  month = dec,
  volume = {122},
  pages = {321--331},
  publisher = {{Wiley}},
  doi = {10.1111/j.1600-0706.2012.00299.x},
  journal = {Oikos},
  number = {3}
}

@article{bahn2012a,
  title = {Testing the Predictive Performance of Distribution Models},
  author = {Bahn, Volker and McGill, Brian J.},
  year = {2012},
  month = dec,
  volume = {122},
  pages = {321--331},
  publisher = {Wiley-Blackwell},
  doi = {10.1111/j.1600-0706.2012.00299.x},
  annotation = {00106},
  journal = {Oikos},
  number = {3}
}

@article{blockCV,
  title = {{{blockCV}}: {{An R}} Package for Generating Spatially or Environmentally Separated Folds for k-Fold Cross-Validation of Species Distribution Models},
  author = {Valavi, Roozbeh and Elith, Jane and {Lahoz-Monfort}, Jos{\'e} J. and {Guillera-Arroita}, Gurutzeta and Valavi, Roozbeh and Elith, Jane and {Lahoz-Monfort}, Jos{\'e} J. and {Guillera-Arroita}, Gurutzeta},
  year = {2019},
  volume = {10},
  pages = {225--232},
  doi = {10.1111/2041-210X.13107},
  journal = {Methods in Ecology and Evolution},
  number = {2}
}

@article{boettiger2015,
  title = {Building {{Software}}, {{Building Community}}: {{Lessons}} from the {{rOpenSci Project}}},
  shorttitle = {Building {{Software}}, {{Building Community}}},
  author = {Boettiger, Carl and Chamberlain, Scott and Hart, Edmund and Ram, Karthik},
  year = {2015},
  month = nov,
  volume = {3},
  pages = {e8},
  publisher = {{Ubiquity Press}},
  issn = {2049-9647},
  doi = {10.5334/jors.bu},
  abstract = {rOpenSci is a developer collective originally formed in 2011 by graduate students and post-docs from ecology and evolutionary biology to collaborate on building software tools to facilitate a more open and synthetic approach in the face of transformative rise of large and heterogeneous data. Born on the internet (the collective only began through chance discussions over social media), we have grown into a widely recognized effort that supports an ecosystem of some 45 software packages, engages scores of collaborators, has taught dozens of workshops around the world, and has secured over \$480,000 in grant support. As young scientists working in an academic context largely without direct support for our efforts, we have first hand experience with most of the the technical and social challenges WSSSPE seeks to address. In this paper we provide an experience report which describes our approach and success in building an effective and diverse community.},
  copyright = {Authors who publish with this journal agree to the following terms:    Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a  Creative Commons Attribution License  that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.  Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.  Authors are permitted and encouraged to post their work online (e.g., in institutional repositories or on their website) prior to and during the submission process, as it can lead to productive exchanges, as well as earlier and greater citation of published work (See  The Effect of Open Access ).  All third-party images reproduced on this journal are shared under Educational Fair Use. For more information on  Educational Fair Use , please see  this useful checklist prepared by Columbia University Libraries .   All copyright  of third-party content posted here for research purposes belongs to its original owners.  Unless otherwise stated all references to characters and comic art presented on this journal are \textcopyright, \textregistered{} or \texttrademark{} of their respective owners. No challenge to any owner's rights is intended or should be inferred.},
  file = {/Users/pjs/Zotero/storage/WK8VQF24/Boettiger et al. - 2015 - Building Software, Building Community Lessons fro.pdf;/Users/pjs/Zotero/storage/ISPBMQEC/jors.bu.html},
  journal = {Journal of Open Research Software},
  keywords = {data science,open science,R,ropensci},
  language = {en},
  number = {1}
}

@article{brenning2005,
  title = {Spatial Prediction Models for Landslide Hazards: Review, Comparison and Evaluation},
  shorttitle = {Spatial Prediction Models for Landslide Hazards},
  author = {Brenning, A.},
  year = {2005},
  month = nov,
  volume = {5},
  pages = {853--862},
  publisher = {{Copernicus GmbH}},
  issn = {1561-8633},
  doi = {10.5194/nhess-5-853-2005},
  abstract = {{$<$}p{$><$}strong class="journal-contentHeaderColor"{$>$}Abstract.{$<$}/strong{$>$} The predictive power of logistic regression, support vector machines and bootstrap-aggregated classification trees (bagging, double-bagging) is compared using misclassification error rates on independent test data sets. Based on a resampling approach that takes into account spatial autocorrelation, error rates for predicting "present" and "future" landslides are estimated within and outside the training area. In a case study from the Ecuadorian Andes, logistic regression with stepwise backward variable selection yields lowest error rates and demonstrates the best generalization capabilities. The evaluation outside the training area reveals that tree-based methods tend to overfit the data.{$<$}/p{$>$}},
  file = {/Users/pjs/Zotero/storage/FMCVSXW3/Brenning - 2005 - Spatial prediction models for landslide hazards r.pdf;/Users/pjs/Zotero/storage/TPVW3XYX/2005.html},
  journal = {Natural Hazards and Earth System Sciences},
  language = {English},
  number = {6}
}

@article{brenning2008,
  title = {Estimating Error Rates in the Classification of Paired Organs},
  author = {Brenning, Alexander and Lausen, Berthold},
  year = {2008},
  month = sep,
  volume = {27},
  pages = {4515--4531},
  issn = {0277-6715},
  doi = {10.1002/sim.3310},
  abstract = {Clinical data from paired organs present a dependence structure that has to be considered when making statistical inference or evaluating classification rules with resampling-based techniques (bootstrap, cross-validation). We introduce a paired cross-validation approach for the estimation of misclassification error rates in the classification of data from paired organs. The dependence structure of the sample is honored by subject-level cross-validation. Theoretical considerations as well as a case-control study on glaucoma diagnosis and a simulation study show that the variance of the paired cross-validation estimator is considerably lower than in traditional cross-validation error estimation on one randomly selected eye per subject. The actual variance reduction is mainly controlled by the contribution of differential misclassification between both eyes to the overall error rate. By contrast, 'ad hoc' cross-validation ignoring the autocorrelation of paired organs leads to biased error estimates. Using the double-bagging technique, we also show that classification accuracy can be improved by using information from both eyes in training machine-learning classifiers. In glaucoma detection, the reduction in misclassification error rates by training data from both eyes is equivalent to an increase in the sample size by one-third to one-half, which is an important achievement in clinical studies.},
  journal = {Statistics in Medicine},
  keywords = {Bias,Case-Control Studies,Computer Simulation,Data Interpretation; Statistical,Diagnostic Errors,Glaucoma,Humans,Middle Aged,Registries,Reproducibility of Results,Sensitivity and Specificity},
  language = {eng},
  number = {22},
  pmid = {18465836}
}

@inproceedings{brenning2012,
  title = {Spatial Cross-Validation and Bootstrap for the Assessment of Prediction Rules in Remote Sensing: {{The R}} Package Sperrorest},
  booktitle = {2012 {{IEEE}} International Geoscience and Remote Sensing Symposium},
  author = {Brenning, Alexander},
  year = {2012},
  month = jul,
  publisher = {{IEEE}},
  doi = {10.1109/igarss.2012.6352393}
}

@manual{CAST,
  title = {{{CAST}}: 'caret' Applications for Spatial-Temporal Models},
  author = {Meyer, Hanna},
  year = {2020},
  type = {Manual}
}

@inproceedings{cluto,
  title = {Evaluation of Hierarchical Clustering Algorithms for Document Datasets},
  booktitle = {Proceedings of the Eleventh International Conference on {{Information}} and Knowledge Management},
  author = {Zhao, Ying and Karypis, George},
  year = {2002},
  pages = {515--524}
}

@book{cressie1993,
  title = {Statistics for {{Spatial Data}}},
  author = {Cressie, Noel A. C.},
  year = {1993},
  month = sep,
  publisher = {{John Wiley \& Sons, Inc.}},
  doi = {10.1002/9781119115151},
  annotation = {18949}
}

@article{efron1983,
  title = {A {{Leisurely Look}} at the {{Bootstrap}}, the {{Jackknife}}, and {{Cross}}-{{Validation}}},
  author = {Efron, Bradley and Gong, Gail},
  year = {1983},
  month = feb,
  volume = {37},
  pages = {36--48},
  publisher = {{Taylor \& Francis}},
  issn = {0003-1305},
  doi = {10.1080/00031305.1983.10483087},
  abstract = {This is an invited expository article for The American Statistician. It reviews the nonparametric estimation of statistical error, mainly the bias and standard error of an estimator, or the error rate of a prediction rule. The presentation is written at a relaxed mathematical level, omitting most proofs, regularity conditions, and technical details.},
  annotation = {\_eprint: https://www.tandfonline.com/doi/pdf/10.1080/00031305.1983.10483087},
  file = {/Users/pjs/Zotero/storage/VMBWZL6J/00031305.1983.html},
  journal = {The American Statistician},
  keywords = {Bias estimation,Error rate prediction,Nonparametric confidence intervals,Nonparametric standard errors,Variance estimation},
  number = {1}
}

@manual{fleck2020,
  title = {Lgr: {{A}} Fully Featured Logging Framework},
  author = {Fleck, Stefan},
  year = {2020},
  type = {Manual}
}

@book{ggplot2,
  title = {Ggplot2: {{Elegant}} Graphics for Data Analysis},
  author = {Wickham, Hadley},
  year = {2016},
  publisher = {{Springer-Verlag New York}},
  isbn = {978-3-319-24277-4}
}

@inproceedings{hartigan1979,
  title = {A K-Means Clustering Algorithm},
  author = {Hartigan, J. and Wong, M.},
  year = {1979},
  doi = {10.2307/2346830},
  abstract = {Semantic Scholar extracted view of "A k-means clustering algorithm" by J. Hartigan et al.}
}

@article{hartigan1979a,
  title = {Algorithm {{AS}} 136: {{A K}}-{{Means Clustering Algorithm}}},
  shorttitle = {Algorithm {{AS}} 136},
  author = {Hartigan, J. A. and Wong, M. A.},
  year = {1979},
  volume = {28},
  pages = {100--108},
  publisher = {{[Wiley, Royal Statistical Society]}},
  issn = {0035-9254},
  doi = {10.2307/2346830},
  journal = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
  number = {1}
}

@book{hastie2001,
  title = {The Elements of Statistical Learning},
  author = {Hastie, Trevor and Friedman, Jerome and Tibshirani, Robert},
  year = {2001},
  publisher = {{Springer New York}},
  doi = {10.1007/978-0-387-21606-5}
}

@article{hornik2012,
  title = {The {{Comprehensive R Archive Network}}},
  author = {Hornik, Kurt},
  year = {2012},
  volume = {4},
  pages = {394--398},
  issn = {1939-0068},
  doi = {10.1002/wics.1212},
  abstract = {The Comprehensive R Archive Network (CRAN) is a network of sites acting as the primary web service distributing R sources and binaries, extension packages, and documentation. We discuss this functionality in more detail, with particular emphasis on the CRAN package repository, and its underlying design and operation principles. WIREs Comput Stat 2012 doi: 10.1002/wics.1212 This article is categorized under: Applications of Computational Statistics {$>$} Organizations and Publications},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/wics.1212},
  file = {/Users/pjs/Zotero/storage/XVBTFLVI/wics.html},
  journal = {WIREs Computational Statistics},
  keywords = {collaborative software development,knowledge domain,R,R package repositories,R sources and binaries,software quality,statistical computing},
  language = {en},
  number = {4}
}

@article{karasiak2021,
  title = {Spatial Dependence between Training and Test Sets: Another Pitfall of Classification Accuracy Assessment in Remote Sensing},
  shorttitle = {Spatial Dependence between Training and Test Sets},
  author = {Karasiak, N. and Dejoux, J.-F. and Monteil, C. and Sheeren, D.},
  year = {2021},
  month = apr,
  issn = {1573-0565},
  doi = {10.1007/s10994-021-05972-1},
  abstract = {Spatial autocorrelation is inherent to remotely sensed data. Nearby pixels are more similar than distant ones. This property can help to improve the classification performance, by adding spatial or contextual features into the model. However, it can also lead to overestimation of generalisation capabilities, if the spatial dependence between training and test sets is ignored. In this paper, we review existing approaches that deal with spatial autocorrelation for image classification in remote sensing and demonstrate the importance of bias in accuracy metrics when spatial independence between the training and test sets is not respected. We compare three spatial and non-spatial cross-validation strategies at pixel and object levels and study how performances vary at different sample sizes. Experiments based on Sentinel-2 data for mapping two simple forest classes show that spatial leave-one-out cross-validation is the better strategy to provide unbiased estimates of predictive error. Its performance metrics are consistent with the real quality of the resulting map contrary to traditional non-spatial cross-validation that overestimates accuracy. This highlight the need to change practices in classification accuracy assessment. To encourage it we developped Museo ToolBox, an open-source python library that makes spatial cross-validation possible.},
  file = {/Users/pjs/Zotero/storage/KRG8UU2R/Karasiak et al. - 2021 - Spatial dependence between training and test sets.pdf},
  journal = {Machine Learning},
  language = {en}
}

@article{kasurak2011,
  title = {Linear Mixed Modelling of Snow Distribution in the Central {{Yukon}}},
  author = {Kasurak, Andrew and Kelly, Richard and Brenning, Alexander},
  year = {2011},
  volume = {25},
  pages = {3332--3346},
  issn = {1099-1085},
  doi = {10.1002/hyp.8168},
  abstract = {Remote sensing estimates of snow water equivalent (SWE) in mountainous areas are subject to large uncertainties. As a prerequisite for testing passive microwave algorithm estimations of SWE, this study aims to collect snow depth (SD) data and provide an understanding of its complex spatial structure as part of the Canadian International Polar Year observations theme. Snow accumulation, redistribution and ablation are controlled by processes that depend on a variety of topographic factors as well as land surface characteristics, which leads us to modelling SD as a function of proxy variables derived from digital elevation model and Landsat data. Field measurements were performed at 3924 locations compromising 184 sites in 50 transects over 2 years. These measurements were used to predict SD over the study area using a spatial linear mixed-effects model, a model type capable of handling the hierarchical structure of the field data. The model, built using stepwise variable selection, uses as predictor variables transformed elevation, slope, the logarithm of slope, potential incoming solar radiation and its transform; the normalized difference vegetation index, and a transformed tasseled cap brightness from Landsat imagery. A second, simpler model links SD with density giving SWE. The cross-validated root mean squared error of the SD distribution model was 14 cm around an overall mean of 80 cm over a domain of 250 \texttimes{} 250 km. This instantaneous end-of-season peak-accumulation snow map will enable the validation of satellite remote sensing over a generally inaccessible area. Copyright \textcopyright{} 2011 John Wiley \& Sons, Ltd.},
  annotation = {\_eprint: https://www.onlinelibrary.wiley.com/doi/pdf/10.1002/hyp.8168},
  copyright = {Copyright \textcopyright{} 2011 John Wiley \& Sons, Ltd.},
  file = {/Users/pjs/Zotero/storage/XJE4YCNB/hyp.html},
  journal = {Hydrological Processes},
  keywords = {mixed-effects regression,snow hydrology,snow survey,snow water equivalent,spatial linear mixed-effects model,Yukon mountains},
  language = {en},
  number = {21}
}

@article{legendre1993,
  title = {Spatial Autocorrelation: {{Trouble}} or New Paradigm?},
  author = {Legendre, Pierre},
  year = {1993},
  month = sep,
  volume = {74},
  pages = {1659--1673},
  publisher = {{Wiley}},
  doi = {10.2307/1939924},
  journal = {Ecology},
  number = {6}
}

@book{lovelace2019,
  title = {Geocomputation with {{R}}},
  author = {Lovelace, Robin and Nowosad, Jakub and Muenchow, Jannes},
  year = {2019},
  publisher = {{CRC Press}}
}

@article{martin2008,
  title = {A Generalizable Method for Remote Sensing of Canopy Nitrogen across a Wide Range of Forest Ecosystems},
  author = {Martin, M. E. and Plourde, L. C. and Ollinger, S. V. and Smith, M. -L. and McNeil, B. E.},
  year = {2008},
  month = sep,
  volume = {112},
  pages = {3511--3519},
  issn = {0034-4257},
  doi = {10.1016/j.rse.2008.04.008},
  abstract = {A growing number of investigations have shown that remote sensing of foliar nitrogen (N) concentration in plant canopies can be achieved with imaging spectroscopy, or hyperspectral remote sensing, from satellite or airborne sensors. Development of this approach has been fueled by recognition that foliar N is related to a variety of ecological and biogeochemical processes, ranging from the spread of invasive species to the ecosystem effects of insect defoliation events to patterns of N cycling in forest soils. To date, most studies have focused on building site-specific foliar N detection algorithms applied to individual scenes or small landscapes that have been intensively characterized with local field measurements. However, the growing number of well-measured sites, combined with improvements in image data quality and processing methods provide an opportunity to begin seeking more general N detection methods that can be applied to a broader range of sites or to locations that lack intensive field measurements. Here, we combine data from several independent efforts in North America, Central America and Australia, to examine whether development of calibration methods to determine canopy nitrogen concentration across a wide range of forest ecosystems is possible. The analysis included data from 137 individual field plots within eight study sites for which imagery has been acquired from NASA's Airborne Visible/Infrared Imaging Spectrometer (AVIRIS) and/or Hyperion instruments. The combined dataset was used to evaluate site-specific calibration results as well as results obtained with data pooled across all sites. We evaluated the accuracy of results using plot- and site-level cross-validation wherein individual plots or entire sites were withheld and used as an independent validation of the resulting algorithms. In instances where all sites were represented in the calibration, canopy-level foliar N concentration was predicted to within 7\textendash 15\% of the mean field-measured values indicating a strong potential for broadly applied foliar N detection. When whole sites were iteratively dropped from the calibration and predicted by remaining data, predictions were still significant, but less accurate (7\textendash 47\% of mean canopy-level N concentration). This suggests that further development to include a wider range of ecosystems will be necessary before cross-site prediction accuracy approaches that seen in site-specific calibrations. Nevertheless, we view these results as promising, particularly given the potential value of foliar N estimates, even at a reduced level of confidence, at sites for which there is no possibility of conducting field data collections.},
  file = {/Users/pjs/Zotero/storage/H3SLT82Q/Martin et al. - 2008 - A generalizable method for remote sensing of canop.pdf;/Users/pjs/Zotero/storage/8Z4PVEAR/S0034425708001417.html},
  journal = {Remote Sensing of Environment},
  keywords = {AVIRIS,Foliar nitrogen,Hyperion,Hyperspectral,Remote sensing},
  language = {en},
  number = {9}
}

@article{meyer2018,
  title = {Improving Performance of Spatio-Temporal Machine Learning Models Using Forward Feature Selection and Target-Oriented Validation},
  author = {Meyer, Hanna and Reudenbach, Christoph and Hengl, Tomislav and Katurji, Marwan and Nauss, Thomas},
  year = {2018},
  month = mar,
  volume = {101},
  pages = {1--9},
  issn = {1364-8152},
  doi = {10.1016/j.envsoft.2017.12.001},
  abstract = {Importance of target-oriented validation strategies for spatio-temporal prediction models is illustrated using two case studies: (1) modelling of air temperature (Tair) in Antarctica, and (2) modelling of volumetric water content (VW) for the R.J. Cook Agronomy Farm, USA. Performance of a random k-fold cross-validation (CV) was compared to three target-oriented strategies: Leave-Location-Out (LLO), Leave-Time-Out (LTO), and Leave-Location-and-Time-Out (LLTO) CV. Results indicate that considerable differences between random k-fold (R2~=~0.9 for Tair and 0.92 for VW) and target-oriented CV (LLO R2~=~0.24 for Tair and 0.49 for VW) exist, highlighting the need for target-oriented validation to avoid an overoptimistic view on models. Differences between random k-fold and target-oriented CV indicate spatial over-fitting caused by misleading variables. To decrease over-fitting, a forward feature selection in conjunction with target-oriented CV is proposed. It decreased over-fitting and simultaneously improved target-oriented performances (LLO CV R2~=~0.47 for Tair and 0.55 for VW).},
  file = {/Users/pjs/Zotero/storage/HBJWWT83/Meyer et al. - 2018 - Improving performance of spatio-temporal machine l.pdf;/Users/pjs/Zotero/storage/CKRR47XD/S1364815217310976.html},
  journal = {Environmental Modelling \& Software},
  keywords = {Cross-validation,Feature selection,Over-fitting,Random forest,Spatio-temporal,Target-oriented validation},
  language = {en}
}

@article{meyer2018a,
  title = {Improving Performance of Spatio-Temporal Machine Learning Models Using Forward Feature Selection and Target-Oriented Validation},
  author = {Meyer, Hanna and Reudenbach, Christoph and Hengl, Tomislav and Katurji, Marwan and Nauss, Thomas},
  year = {2018},
  month = mar,
  volume = {101},
  pages = {1--9},
  publisher = {Elsevier BV},
  doi = {10.1016/j.envsoft.2017.12.001},
  annotation = {ZSCC: 0000031  00000},
  file = {/Users/pjs/Zotero/storage/QN9MM6MG/Meyer et al. - 2018 - Improving performance of spatio-temporal machine l.pdf;/Users/pjs/Zotero/storage/92R23HZC/S1364815217310976.html},
  journal = {Environmental Modelling \& Software},
  keywords = {Cross-validation,Feature selection,Over-fitting,Random forest,spatial cross-validation,Spatio-temporal,Target-oriented validation}
}

@article{milligan2000,
  title = {Construction and {{Assessment}} of {{Classification Rules}}, by {{D}}.{{J}}. {{Hand}}},
  author = {Milligan, G.W.},
  year = {2000},
  month = jul,
  volume = {17},
  pages = {355--356},
  issn = {1432-1343},
  doi = {10.1007/s003570000025},
  file = {/Users/pjs/Zotero/storage/AB4YQMVA/Milligan - 2000 - Construction and Assessment of Classification Rule.pdf},
  journal = {Journal of Classification},
  language = {en},
  number = {2}
}

@article{mlr3,
  title = {{{mlr3}}: {{A}} Modern Object-Oriented Machine Learning Framework in {{R}}},
  author = {Lang, Michel and Binder, Martin and Richter, Jakob and Schratz, Patrick and Pfisterer, Florian and Coors, Stefan and Au, Quay and Casalicchio, Giuseppe and Kotthoff, Lars and Bischl, Bernd},
  year = {2019},
  month = dec,
  doi = {10.21105/joss.01903},
  journal = {Journal of Open Source Software}
}

@article{mlr3book,
  title = {Mlr3 Book},
  author = {Becker, Marc and Binder, Martin and Bischl, Bernd and Lang, Michel and Pfisterer, Florian and Reich, Nicholas G. and Richter, Jakob and Schratz, Patrick and Sonabend, Raphael},
  year = {2020},
  month = oct
}

@manual{mlr3learners,
  title = {Mlr3learners: {{Recommended Learners}} for 'Mlr3'},
  author = {Lang, Michel and Au, Quay and Coors, Stefan and Schratz, Patrick},
  year = {2020},
  type = {Manual}
}

@article{muenchow2012,
  title = {Geomorphic Process Rates of Landslides along a Humidity Gradient in the Tropical {{Andes}}},
  author = {Muenchow, J. and Brenning, A. and Richter, M.},
  year = {2012},
  volume = {139-140},
  pages = {271--284},
  issn = {0169-555X},
  doi = {10.1016/j.geomorph.2011.10.029},
  journal = {Geomorphology},
  keywords = {Denudation rate,Generalized additive model,Geomorphic work,Mass movements}
}

@article{pebesma2018,
  title = {Simple {{Features}} for {{R}}: {{Standardized Support}} for {{Spatial Vector Data}}},
  shorttitle = {Simple {{Features}} for {{R}}},
  author = {Pebesma, Edzer},
  year = {2018},
  volume = {10},
  pages = {439--446},
  issn = {2073-4859},
  file = {/Users/pjs/Zotero/storage/N74RGX4S/index.html},
  journal = {The R Journal},
  language = {en},
  number = {1}
}

@article{pena2015,
  title = {Assessing Fruit-Tree Crop Classification from {{Landsat}}-8 Time Series for the {{Maipo Valley}}, {{Chile}}},
  author = {Pe{\~n}a, M.A. and Brenning, A.},
  year = {2015},
  month = dec,
  volume = {171},
  pages = {234--244},
  publisher = {Elsevier BV},
  doi = {10.1016/j.rse.2015.10.029},
  annotation = {ZSCC: 0000063  00000},
  file = {/Users/pjs/Zotero/storage/R4DKDHMS/Peña and Brenning - 2015 - Assessing fruit-tree crop classification from Land.pdf;/Users/pjs/Zotero/storage/UFQKTZXY/Peña and Brenning - 2015 - Assessing fruit-tree crop classification from Land.pdf;/Users/pjs/Zotero/storage/WV22JSG9/S0034425715301814.html;/Users/pjs/Zotero/storage/XI6SZ27U/S0034425715301814.html},
  journal = {Remote Sensing of Environment},
  keywords = {Crop type classification,Landsat-8,NDVI temporal profile,Satellite image time series}
}

@book{plotly,
  title = {Interactive Web-Based Data Visualization with r, Plotly, and Shiny},
  author = {Sievert, Carson},
  year = {2020},
  publisher = {{Chapman and Hall/CRC}},
  isbn = {978-1-138-33145-7}
}

@article{pohjankukka2017,
  title = {Estimating the Prediction Performance of Spatial Models via Spatial K-Fold Cross Validation},
  author = {Pohjankukka, Jonne and Pahikkala, Tapio and Nevalainen, Paavo and Heikkonen, Jukka},
  year = {2017},
  month = jul,
  volume = {31},
  pages = {2001--2019},
  publisher = {{Informa UK Limited}},
  doi = {10.1080/13658816.2017.1346255},
  journal = {International Journal of Geographical Information Science},
  number = {10}
}

@article{ranger,
  title = {Ranger: {{A Fast Implementation}} of {{Random Forests}} for {{High Dimensional Data}} in {{C}}++ and {{R}}},
  author = {Wright, Marvin N. and Ziegler, Andreas},
  year = {2017},
  volume = {77},
  pages = {1--17},
  doi = {10.18637/jss.v077.i01},
  annotation = {00000},
  journal = {Journal of Statistical Software},
  number = {1}
}

@book{raymond2003,
  title = {The Art of {{Unix}} Programming},
  author = {Raymond, Eric S},
  year = {2003},
  publisher = {{Addison-Wesley Professional}}
}

@article{rest2014,
  title = {Spatial Leave-One-out Cross-Validation for Variable Selection in the Presence of Spatial Autocorrelation},
  author = {Rest, K{\'e}vin Le and Pinaud, David and Monestiez, Pascal and Chadoeuf, Jo{\"e}l and Bretagnolle, Vincent},
  year = {2014},
  volume = {23},
  pages = {811--820},
  issn = {1466-8238},
  doi = {10.1111/geb.12161},
  abstract = {Aim Processes and variables measured in ecology are almost always spatially autocorrelated, potentially leading to the choice of overly complex models when performing variable selection. One way to solve this problem is to account for residual spatial autocorrelation (RSA) for each subset of variables considered and then use a classical model selection criterion such as the Akaike information criterion (AIC). However, this method can be laborious and it raises other concerns such as which spatial model to use or how to compare different spatial models. To improve the accuracy of variable selection in ecology, this study evaluates an alternative method based on a spatial cross-validation procedure. Such a procedure is usually used for model evaluation but can also provide interesting outcomes for variable selection in the presence of spatial autocorrelation. Innovation We propose to use a special case of spatial cross-validation, spatial leave-one-out (SLOO), giving a criterion equivalent to the AIC in the absence of spatial autocorrelation. SLOO only computes non-spatial models and uses a threshold distance (equal to the range of RSA) to keep each point left out spatially independent from the others. We first provide some simulations to evaluate how SLOO performs compared with AIC. We then assess the robustness of SLOO on a large-scale dataset. R software codes are provided for generalized linear models. Main conclusions The AIC was relevant for variable selection in the presence of RSA if the independent variables considered were not spatially autocorrelated. It otherwise failed because highly spatially autocorrelated variables were more often selected than others. Conversely, SLOO had similar performances whether the variables were themselves spatially autocorrelated or not. It was particularly useful when the range of RSA was small, which is a common property of spatial tools. SLOO appears to be a promising solution for selecting relevant variables from most ecological spatial datasets.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/geb.12161},
  copyright = {\textcopyright{} 2014 John Wiley \& Sons Ltd},
  file = {/Users/pjs/Zotero/storage/M8QXYPJ2/Rest et al. - 2014 - Spatial leave-one-out cross-validation for variabl.pdf;/Users/pjs/Zotero/storage/3KMF2EF5/geb.html},
  journal = {Global Ecology and Biogeography},
  keywords = {AIC,common buzzard Buteo buteo,GLM,residual spatial autocorrelation,simulations,spatial cross-validation},
  language = {en},
  number = {7}
}

@article{roberts2017,
  title = {Cross-Validation Strategies for Data with Temporal, Spatial, Hierarchical, or Phylogenetic Structure},
  author = {Roberts, David R. and Bahn, Volker and Ciuti, Simone and Boyce, Mark S. and Elith, Jane and {Guillera-Arroita}, Gurutzeta and Hauenstein, Severin and {Lahoz-Monfort}, Jos{\'e} J. and Schr{\"o}der, Boris and Thuiller, Wilfried and Warton, David I. and Wintle, Brendan A. and Hartig, Florian and Dormann, Carsten F.},
  year = {2017},
  month = mar,
  volume = {40},
  pages = {913--929},
  publisher = {{Wiley}},
  doi = {10.1111/ecog.02881},
  journal = {Ecography},
  number = {8}
}

@article{schratz2019,
  title = {Hyperparameter Tuning and Performance Assessment of Statistical and Machine-Learning Algorithms Using Spatial Data},
  author = {Schratz, Patrick and Muenchow, Jannes and Iturritxa, Eugenia and Richter, Jakob and Brenning, Alexander},
  year = {2019},
  month = aug,
  volume = {406},
  pages = {109--120},
  publisher = {{Elsevier BV}},
  doi = {10.1016/j.ecolmodel.2019.06.002},
  journal = {Ecological Modelling}
}

@incollection{thompson2012,
  title = {Sampling, {{Third Edition}}},
  booktitle = {Sampling},
  author = {Thompson, Steven K.},
  year = {2012},
  pages = {i-xxi},
  publisher = {{John Wiley \& Sons, Ltd}},
  doi = {10.1002/9781118162934.fmatter},
  abstract = {The prelims comprise: Half Title Wiley Series Page Title Copyright Contents Preface Preface to the Second Edition Preface to the First Edition},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9781118162934.fmatter},
  file = {/Users/pjs/Zotero/storage/JZMKU2PC/2012 - Frontmatter.pdf;/Users/pjs/Zotero/storage/CGRDYDV4/9781118162934.html},
  isbn = {978-1-118-16293-4},
  language = {en}
}

@article{wade1999,
  title = {Construction and {{Assessment}} of {{Classification Rules}}},
  author = {Wade, Mark R.},
  year = {1999},
  month = aug,
  volume = {41},
  pages = {267--267},
  publisher = {{Taylor \& Francis}},
  issn = {0040-1706},
  doi = {10.1080/00401706.1999.10485683},
  annotation = {\_eprint: https://www.tandfonline.com/doi/pdf/10.1080/00401706.1999.10485683},
  journal = {Technometrics},
  number = {3}
}

@article{wenger2012,
  title = {Assessing Transferability of Ecological Models: An Underappreciated Aspect of Statistical Validation},
  author = {Wenger, Seth J. and Olden, Julian D.},
  year = {2012},
  month = jan,
  volume = {3},
  pages = {260--267},
  publisher = {{Wiley}},
  doi = {10.1111/j.2041-210x.2011.00170.x},
  journal = {Methods in Ecology and Evolution},
  number = {2}
}

@article{wenger2012a,
  title = {Assessing Transferability of Ecological Models: An Underappreciated Aspect of Statistical Validation},
  author = {Wenger, Seth J. and Olden, Julian D.},
  year = {2012},
  month = jan,
  volume = {3},
  pages = {260--267},
  publisher = {Wiley-Blackwell},
  doi = {10.1111/j.2041-210x.2011.00170.x},
  annotation = {00000},
  journal = {Methods in Ecology and Evolution},
  number = {2}
}

@article{wickham2019,
  title = {Welcome to the {{tidyverse}}},
  author = {Wickham, Hadley and Averick, Mara and Bryan, Jennifer and Chang, Winston and McGowan, Lucy D'Agostino and Fran{\c c}ois, Romain and Grolemund, Garrett and Hayes, Alex and Henry, Lionel and Hester, Jim and Kuhn, Max and Pedersen, Thomas Lin and Miller, Evan and Bache, Stephan Milton and M{\"u}ller, Kirill and Ooms, Jeroen and Robinson, David and Seidel, Dana Paige and Spinu, Vitalie and Takahashi, Kohske and Vaughan, Davis and Wilke, Claus and Woo, Kara and Yutani, Hiroaki},
  year = {2019},
  volume = {4},
  pages = {1686},
  doi = {10.21105/joss.01686},
  journal = {Journal of Open Source Software},
  number = {43}
}

@article{wickham2019a,
  title = {Welcome to the {{Tidyverse}}},
  author = {Wickham, Hadley and Averick, Mara and Bryan, Jennifer and Chang, Winston and McGowan, Lucy D'Agostino and Fran{\c c}ois, Romain and Grolemund, Garrett and Hayes, Alex and Henry, Lionel and Hester, Jim and Kuhn, Max and Pedersen, Thomas Lin and Miller, Evan and Bache, Stephan Milton and M{\"u}ller, Kirill and Ooms, Jeroen and Robinson, David and Seidel, Dana Paige and Spinu, Vitalie and Takahashi, Kohske and Vaughan, Davis and Wilke, Claus and Woo, Kara and Yutani, Hiroaki},
  year = {2019},
  month = nov,
  volume = {4},
  pages = {1686},
  issn = {2475-9066},
  doi = {10.21105/joss.01686},
  abstract = {Wickham et al., (2019). Welcome to the Tidyverse. Journal of Open Source Software, 4(43), 1686, https://doi.org/10.21105/joss.01686},
  file = {/Users/pjs/Zotero/storage/TPTLUV9E/Wickham et al. - 2019 - Welcome to the Tidyverse.pdf;/Users/pjs/Zotero/storage/KTY9M6VT/joss.html},
  journal = {Journal of Open Source Software},
  language = {en},
  number = {43}
}

@article{willmott2006,
  title = {On the Use of Dimensioned Measures of Error to Evaluate the Performance of Spatial Interpolators},
  author = {Willmott, C. J. and Matsuura, K.},
  year = {2006},
  month = jan,
  volume = {20},
  pages = {89--102},
  publisher = {{Taylor \& Francis}},
  issn = {1365-8816},
  doi = {10.1080/13658810500286976},
  abstract = {Spatial cross-validation and average-error statistics are examined with respect to their abilities to evaluate alternate spatial interpolation methods. A simple cross-validation methodology is described, and the relative abilities of three, dimensioned error statistics\textemdash the root-mean-square error (RMSE), the mean absolute error (MAE), and the mean bias error (MBE)\textemdash to describe average interpolator performance are examined. To illustrate our points, climatologically averaged weather-station temperatures were obtained from the Global Historical Climatology Network (GHCN), Version 2, and then alternately interpolated spatially (gridded) using two spatial-interpolation procedures. Substantial differences in the performance of our two spatial interpolators are evident in maps of the cross-validation error fields, in the average-error statistics, as well as in estimated land-surface-average air temperatures that differ by more than 2\textdegree C. The RMSE and its square, the mean-square error (MSE), are of particular interest, because they are the most widely reported average-error measures, and they tend to be misleading. It (RMSE) is an inappropriate measure of average error because it is a function of three characteristics of a set of errors, rather than of one (the average error). Our findings indicate that MAE and MBE are natural measures of average error and that (unlike RMSE) they are unambiguous.},
  annotation = {\_eprint: https://doi.org/10.1080/13658810500286976},
  file = {/Users/pjs/Zotero/storage/K87BKQHY/13658810500286976.html},
  journal = {International Journal of Geographical Information Science},
  keywords = {Error measures,Spatial interpolators},
  number = {1}
}


