\documentclass[
]{jss}

\usepackage[utf8]{inputenc}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

\author{
Patrick Schratz\\Friedrich-Schiller-University Jena \AND Marc
Becker\\Ludwig-Maximilians-University Munich \And Michel Lang\\TU
Dortmund University
}
\title{\pkg{mlr3spatiotempcv}: Spatiotemporal Resampling Methods for
\pkg{mlr3}}

\Plainauthor{Patrick Schratz, Marc Becker, Michel Lang}
\Plaintitle{mlr3spatiotempcv: Spatiotemporal Resampling Methods for
mlr3}

\Abstract{
The R package
\href{https://mlr3spatiotempcv.mlr-org.com}{mlr3spatiotempcv} is an
extension package of the machine learning framework
\href{https://mlr3.mlr-org.com}{mlr3} \citep{mlr3}. It adds support for
spatiotemporal resampling methods and respective visualization methods.
Spatiotemporal resampling methods are needed to account for the
existence of different autocorrelation types (spatial autocorrelation
(SAC), temporal autocorrelation (TAC) or spatio-temporal autocorrelation
(STAC)) in datasets. These autocorrelation types cause biased
performance estimates of varying magnitude in cross-validation when
ignored. At the time of writing, various R packages implementing
different spatiotemporal partitioning strategies exist: CAST
\citep{cast}, blockCV \citep{blockCV} or sperrorest \citep{sperrorest}.
There are some resampling methods used in scientific studies for which
the source code is either not available or a different programming
language has been used \citep{roberts2017, pohjankukka2017} The goal of
\href{https://mlr3spatiotempcv.mlr-org.com}{mlr3spatiotempcv} is to
gather the available spatiotemporal resampling methods in R and make
them available to users through a simplified and generic interface. The
latter is made possible by integrating the package directly into the
\href{https://mlr3.mlr-org.com}{mlr3} machine learning framework. This
simplifies the step of integrating package specific syntax into an
overarching machine learning pipeline. The hope is that the availability
of such a package encourages researchers to more often apply
spatiotemporal resampling methods in scientific case studies.
}

\Keywords{resampling, machine
learning, autocorrelation, spatial, temporal, \proglang{R}}
\Plainkeywords{resampling, machine
learning, autocorrelation, spatial, temporal, R}

%% publication information
%% \Volume{50}
%% \Issue{9}
%% \Month{June}
%% \Year{2012}
%% \Submitdate{}
%% \Acceptdate{2012-06-04}

\Address{
    Patrick Schratz\\
    Friedrich-Schiller-University Jena\\
    Faculty of Chemistry and Earth Sciences\\
Department of Geography\\
GIScience group\\
  E-mail: \email{patrick.schratz@uni-jena.de}\\
  
      Marc Becker\\
    Ludwig-Maximilians-University Munich\\
    Department of Statistics Statistical Learning and Data Science
group\\
  
  
      Michel Lang\\
    TU Dortmund University\\
    Faculty of Statistics\\
  
  
  }

% Pandoc citation processing

% Pandoc header

\usepackage{amsmath} \usepackage{booktabs} \usepackage{longtable}

\begin{document}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

Data which includes spatial or temporal information requires special
treatment in machine learning; similar to cost-sensitive, functional,
multilabel, ordinal or survival datasets \citep{mlr3book}. In contrast
to non-spatial/non-temporal data, observations inherit a natural
grouping, either in space or time or in both space and time
\citep{legendre1993}. This grouping causes observations to be
autocorrelated, either in space (spatial autocorrelation (SAC)), time
(temporal autocorrelation (TAC)) or both space and time (spatiotemporal
autocorrelation (STAC)). For simplicity, the acronym STAC is used as a
generic term in the following discussion for all the different
characteristics introduced above.

\hypertarget{spatiotemporal-autocorrelation-in-statisticalmachine-learning}{%
\subsection{Spatiotemporal Autocorrelation in Statistical/Machine
Learning}\label{spatiotemporal-autocorrelation-in-statisticalmachine-learning}}

The overarching problem is that STAC violates the assumption that the
observations in the train and test datasets are independent
\citep{hastie2001}. If this assumption is violated, the reliability of
the resulting performance estimates, for example retrieved via
cross-validation, is decreased. The magnitude of this decrease is linked
to the magnitude of STAC in the dataset, which cannot be determined
easily.

One approach to account for the existence of STAC is to use dedicated
resampling methods.
\href{https://mlr3spatiotempcv.mlr-org.com}{mlr3spatiotempcv} provides
access to the most frequently used spatiotemporal resampling methods.
The following example, which uses the
\href{https://mlr3spatiotempcv.mlr-org.com/reference/mlr_tasks_ecuador.html}{ecuador}
dataset created by
\href{https://scholar.google.com/citations?user=Slq94Y4AAAAJ\&hl=de\&authuser=1\&oi=ao}{Jannes
Muenchow}, showcases how a spatial dataset can be used to retrieve a
bias-reduced performance estimate of a learner.

This dataset contains information on the occurrence of landslides
(binary) in the Andes of Southern Ecuador. The landslides were mapped
from aerial photos taken in 2000. The dataset is well suited to serve as
an example because it is relatively small and, of course, due to the
spatial nature of the observations. Please refer to \citet{muenchow2012}
for a detailed description of the dataset.

To account for the spatial autocorrelation probably present in the
landslide data, we will make use of one of the most used spatial
partitioning methods, a cluster-based \(k\)-means grouping
\citep{sperrorest}, (\texttt{"spcv\_coords"} in
\href{https://mlr3spatiotempcv.mlr-org.com}{mlr3spatiotempcv}). This
method performs a clustering in 2D space which contrasts with the
commonly used random partitioning for non-spatial data. The grouping has
the effect that train and test data are more separated in space than
they would be by conducting a random partitioning, thereby reducing the
effect of STAC.

By contrast, when using the classical random partitioning approach with
spatial data, train and test observations would be located side-by-side
across the full study area (a visual example is provided further below).
This leads to a high similarity between train and test sets, resulting
in ``better'' but over-optimistic performance estimates in every fold of
a CV compared to the Spatial CV (SpCV) approach. However, these low
error rates are mainly caused due to the STAC in the observations and
the lack of appropriate partitioning methods and not by the power of the
fitted model.

Rephrased: the higher performance results in a non-spatial CV scenario
should not be relied on or used for reporting. The positive bias in
these results is substantial and the actual performance of the model is
nowhere near this result. Results from a SpCV are not unbiased but are
closer in reflecting the actual performance of the learner on unknown
datasets.

\hypertarget{motivation}{%
\subsection{Motivation}\label{motivation}}

In the last years awareness for spatiotemporal autocorrelation in ML
tasks has grown \citep{pohjankukka2017, roberts2017}. Subsequently,
scientists started writing code to account for the issue in their
studies. With R being one of the most used languages with respect to
modeling/statistics and academia in general, R packages were developed
aiming to simplify the data splitting with respect to methods able to
account for spatial autocorrelation \citep[\citet{blockCV}]{cast}.
FIXME: adds refs This is a typical process for the R community as
writing R packages has been made relatively straightforward in recent
years thanks to efforts from various people/organizations such as
Bioconductor, CRAN, ropensci or the tidyverse \citep[\citet{ropensci},
\citet{tidyverse}]{cran} Also the effort of bundling code into a defined
package structure makes it easier for others to re-use it, which is a
good effort towards reproducible science.

The downside of this culture is that ``island solutions'' are being
created, i.e.~small packages which serve a particular (sometimes very
niche) use case. Usually the ``Do one thing and do it well'' UNIX
philosophy is widely known and used in practice \citep{raymond2003art}.
However, the issue with R packages is that not every package is
necessarily easily compatiable with other ones due to differing input
and returns objects, making it problematic to write a clean and tidy
workflow. Also many R packages are written by single persons which not
necessarly have a complete overview over existing implementations. These
points may lead to the following possible issues in practice:

\begin{itemize}
\tightlist
\item
  Different syntax.
\item
  Support for only some predictor types (e.g.~numeric and factor
  features but no ordered factors).
\item
  Different return values.
\item
  Different namings for the same method.
\item
  Unclear longterm maintenance.
\end{itemize}

These points add substantial overhead and/or reproducibility issues for
anyone who wants to make use of the provided implementations within
their studies. \pkg{mlr3spatiotempcv} aims to provide a solution for
some of the points outlined above by wrapping all spatiotemporal
resampling methods available in \proglang{R} packages. By embedding the
package within the \pkg{mlr3} ecosystem and following its unified syntax
and scalable approach, \pkg{mlr3spatiotempcv} aims to provide future
users longterm support for spatiotemporal partitioning methods in R.

\hypertarget{the-mlr3-ecosystem}{%
\subsection{The mlr3 ecosystem}\label{the-mlr3-ecosystem}}

The \pkg{mlr3} R package and its extensions packages form the \pkg{mlr3}
machine learning ecosystem \citep{mlr3}. \pkg{mlr3} aims to wrap many
algorithms available in R to enforce a consistent interface for such.
This adds the ability for simplified benchmarking, visualization and
further model evaluation regardless of the chosen algorithm.

\pkg{mlr3spatiotempcv} complements this philosophy by aiming to apply
the same standards for spatiotemporal resampling methods.

\hypertarget{comparing-spatial-and-non-spatial-resampling}{%
\section{Comparing Spatial and Non-Spatial
Resampling}\label{comparing-spatial-and-non-spatial-resampling}}

To introduce the effect of spatial autocorrelation in modeling, a
spatial and non-spatial CV using \pkg{mlr3spatiotempcv} will be shown in
the following. For simplicity, one of the most used methods (spatial
k-means clustering after \citet{sperrorest}) will be used. Individual
methods are discussed in FIXME.

The performance of a simple classification tree
(\texttt{"classif.ranger"}) is evaluated on a random repeated
cross-validation (\texttt{"repeated\_cv"}) with four folds and two
repetitions. In reality, more fold (between five and ten) and a higher
number of repetitions should be used. The chosen evaluation measure is
the ``Area Under the ROC Curve'' (\texttt{"classif.auc"}) which is a
common evaluation measure for binary responses. The CV will be executed
twice with the only difference being the use of a spatial resampling
object (initialized with \texttt{rsmp("repeated\_spcv\_coords"}) instead
of a non-spatial one (\texttt{rsmp("repeated\_cv"}).

\hypertarget{data-preparation}{%
\subsection{Data Preparation}\label{data-preparation}}

The following code chunk first loads all necessary R packages and sets a
low verbosity for this example. A seed is set for deterministic
execution.

Next the mlr3 task \texttt{"ecuador"}, which is included in
\pkg{mlr3spatiotempcv}, is loaded via \texttt{tsk()}. This function is a
convenience wrapper around the underlying R6 construction method for a
spatiotemporal classification task
(\texttt{mlr3spatiotempcv::TaskClassifST\$new()}).

Last, the random forest learner (\texttt{lrn("classif.ranger")}) is
initialized with default hyperparameters and the prediction type set to
\texttt{"probability"} due to the binary response variable. A set of
commonly used learners is available in \pkg{mlr3learners}
\citep{mlr3learners}, including the random forest implementation after
\citet{ranger}.

By setting the logging threshold, which can be controlled via the
\pkg{lgr} package \citep{lgr}, to \texttt{"warn"}, verbosity is reduced
to keep the example tidy.

\begin{CodeChunk}
\begin{CodeInput}
R> library("mlr3")
R> library("mlr3spatiotempcv")
R> library("mlr3learners")
R> set.seed(42)
R> 
R> # be less verbose
R> lgr::get_logger("bbotk")$set_threshold("warn")
R> lgr::get_logger("mlr3")$set_threshold("warn")
R> 
R> task <- tsk("ecuador")
R> 
R> learner <- lrn("classif.ranger", predict_type = "prob")
\end{CodeInput}
\end{CodeChunk}

\hypertarget{non-spatial-cross-validation}{%
\subsubsection{Non-Spatial
Cross-Validation}\label{non-spatial-cross-validation}}

\begin{CodeChunk}
\begin{CodeInput}
R> resampling_nsp <- rsmp("repeated_cv", folds = 4, repeats = 2)$instantiate(task)
R> rr_nsp <- resample(
+   task = task, learner = learner,
+   resampling = resampling_nsp
+ )
R> 
R> rr_nsp$aggregate(measures = msr("classif.auc"))
\end{CodeInput}
\begin{CodeOutput}
classif.auc 
  0.7600664 
\end{CodeOutput}
\end{CodeChunk}

\hypertarget{spatial-cross-validation}{%
\subsection{Spatial Cross-Validation}\label{spatial-cross-validation}}

\begin{CodeChunk}
\begin{CodeInput}
R> resampling_sp <- rsmp("repeated_spcv_coords", folds = 4, repeats = 2)$instantiate(task)
R> rr_sp <- resample(
+   task = task, learner = learner,
+   resampling = resampling_sp
+ )
R> 
R> rr_sp$aggregate(measures = msr("classif.auc"))
\end{CodeInput}
\begin{CodeOutput}
classif.auc 
  0.6100402 
\end{CodeOutput}
\end{CodeChunk}

Here, the estimated AUC using Non-Spatial Cross-Validation (NSpCV) is
around 0.15 better compared to the Spatial Cross-Validation (SpCV). The
better performance score results from over-optimism in the estimation
with NSpCV. The actual predictive performance on new data is much more
realistically reflected by the performance estimated via SpCV. The
magnitude of this difference is variable as it depends on the dataset,
the magnitude of STAC and the learner itself. Algorithms with a higher
tendency of overfitting to the training set will have a large spread in
such scenarios.

\hypertarget{spatiotemporal-partitioning-methods}{%
\section{Spatiotemporal Partitioning
Methods}\label{spatiotemporal-partitioning-methods}}

At the time of writing, the following spatiotemporal resampling methods
(FIXME ref table) were available across different R packages. This list
might increase over time and it is recommended to consult the homepage
of \pkg{mlr3spatiotempcv} for an up-to-date list.

A low-level introduction is given for every method included at this
point of this article. For a discussion with respect to usage see
section FIXME.

\hypertarget{spatial-buffering}{%
\subsection{Spatial Buffering}\label{spatial-buffering}}

The ``buffering'' method from the \pkg{blockCV} package is conceptually
similar to a leave-one-out (LOO) cross-validation approach
\citep[\citet{blockCV}]{rest2014}. To reduce the similarity between
train and test, a circular buffer around the observations representing
the test set is drawn. Within this buffer zone, all observations are
removed from the training set, thereby reducing the similarity between
train and test set and subsequently the influence of SAC.

By default, the method considers all points for train/test creation. In
an ecological context, this equals to the assumption of having
\emph{presence/absence} data for binary response variables. This means
all non-presence values in the response variable are assumed to be
confirmed absence values.

The implementation also comes with support for
\emph{presence/background} data for binary responses. In this scenario,
only the presence values are considered validated. All other response
observations are assumed to be absent without a proof for this
assumption. When setting argument \texttt{spDataType\ =\ "PB"}, the
method only considers the \emph{presence} observations in a CV scenario.
Background data is used for training the model by default unless
argument \texttt{addBG\ =\ FALSE} is set for which only \emph{presence}
values not falling within the buffer zone of the respective fold are
used for model training.

Due to its similarity to a LOO CV, this method will result in as many
train/test evaluations as observations are present. In the example
below, a buffer zone of 1000 m is used and the first fold shown is
plotted.

\begin{CodeChunk}
\begin{CodeInput}
R> resampling_buffer <- rsmp("spcv_buffer", theRange = 1000)$instantiate(task)
R> 
R> autoplot(resampling_buffer, size = 0.7, task = task, fold_id = 1, crs = 4326) *
+   ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
+   ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
\end{CodeInput}


\begin{center}\includegraphics{paper_files/figure-latex/unnamed-chunk-1-1} \end{center}

\end{CodeChunk}

\hypertarget{spatial-blocking}{%
\subsection{Spatial Blocking}\label{spatial-blocking}}

``Spatial Blocking'' (\pkg{blockCV} package) creates homogeneous blocks
across the study area splitting observations into different zones
\citep[\citet{wenger2012a}]{bahn2012a}. Then, a number of zones is
combined randomly following desired the number of folds. For example, in
a five-fold scenario, the method tries to combines zones to end up with
partitions containing around 20\% of all observations.

The way how the blocks are created can be manifold:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Supplying a numeric value in meters via argument \texttt{theRange}
  (named just \texttt{range} in \{mlr3spatiotempcv\}) will create a
  quadratic block pattern across the study area. The aggregation of
  zones can either be random (default)
  (\texttt{selection\ =\ "random"}), systematic
  (\texttt{selection\ =\ "systematic"}) or checkerboard structure
  (\texttt{selection\ =\ "checkerboard"}).
\end{enumerate}

\texttt{selection\ =\ "random"}

\begin{CodeChunk}
\begin{CodeInput}
R> resampling_block_random <- rsmp("spcv_block", range = 1000, folds = 5)
R> 
R> autoplot(resampling_block_random,
+   size = 0.8, fold_id = 1, task = task, crs = 4326,
+   show_blocks = TRUE, show_labels = TRUE) *
+   ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
+   ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
\end{CodeInput}


\begin{center}\includegraphics{paper_files/figure-latex/unnamed-chunk-2-1} \end{center}

\end{CodeChunk}

\texttt{selection\ =\ "systematic"}: Here, aggregation follows the
linear count from \$1:n\_\{folds\} from top to bottom.

\begin{CodeChunk}
\begin{CodeInput}
R> resampling_block_systematic <- rsmp("spcv_block",
+   range = 1000, folds = 5,
+   selection = "systematic")
R> 
R> autoplot(resampling_block_systematic,
+   size = 0.8, fold_id = 1, task = task, crs = 4326,
+   show_blocks = TRUE, show_labels = TRUE) *
+   ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
+   ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
\end{CodeInput}


\begin{center}\includegraphics{paper_files/figure-latex/unnamed-chunk-3-1} \end{center}

\end{CodeChunk}

\texttt{selection\ =\ "checkerboard"}: This option ignores paramter
\texttt{range} and always creates two partitions following a ``1,2,1,2''
pattern.

\begin{CodeChunk}
\begin{CodeInput}
R> resampling_block_checkerboard <- rsmp("spcv_block",
+   range = 1000, folds = 5,
+   selection = "checkerboard")
R> 
R> autoplot(resampling_block_checkerboard,
+   size = 0.8, fold_id = 1, task = task, crs = 4326,
+   show_blocks = TRUE, show_labels = TRUE) *
+   ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
+   ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
\end{CodeInput}


\begin{center}\includegraphics{paper_files/figure-latex/unnamed-chunk-4-1} \end{center}

\end{CodeChunk}

\hypertarget{environmental-blocking}{%
\subsection{Environmental Blocking}\label{environmental-blocking}}

The last method from the \pkg{blockCV} package, ``environmental
blocking'', makes use of \emph{k-means} clustering \citep{hartigan1979a}
in a possibly multivariate space. The user can specify a variable via
argument \texttt{feature} which levels will be used to create clusters.
Hereby, k-means will use Euclidean distance for cluster creation. Hence,
the selected input variables should be of type numeric. To avoid a
potential bias introduced by features with high variance when selecting
multiple features, all features are standardized by default.

The following example clusters by feature ``distance to forest''.

\begin{CodeChunk}
\begin{CodeInput}
R> resampling_env <- rsmp("spcv_env",
+   features = "distdeforest", folds = 5)
R> 
R> autoplot(resampling_env,
+   size = 0.8, fold_id = 1, task = task, crs = 4326,
+   show_blocks = TRUE, show_labels = TRUE) *
+   ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
+   ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
\end{CodeInput}


\begin{center}\includegraphics{paper_files/figure-latex/unnamed-chunk-5-1} \end{center}

\end{CodeChunk}

It is also possible to cluster by multiple features:

\begin{CodeChunk}
\begin{CodeInput}
R> resampling_env_multi <- rsmp("spcv_env",
+   features = c("distdeforest", "slope"), folds = 5)
R> 
R> autoplot(resampling_env_multi,
+   size = 0.8, fold_id = 1, task = task, crs = 4326,
+   show_blocks = TRUE, show_labels = TRUE) *
+   ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
+   ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
\end{CodeInput}


\begin{center}\includegraphics{paper_files/figure-latex/unnamed-chunk-6-1} \end{center}

\end{CodeChunk}

\hypertarget{spatial-cv}{%
\subsection{Spatial CV}\label{spatial-cv}}

The ``Spatial CV'' method after \citep{sperrorest} and implemented in
package \pkg{sperrorest} is similar to method ``environmental blocking''
in that it also uses \emph{k-means} clustering for fold creation.
However, it does not make use of arbitrary features but uses the
coordinates of all observations to create clusters in the spatial
domain. This is what lead to the naming of \texttt{spcv\_coords} in
\pkg{mlr3spatiotempcv}.

\begin{CodeChunk}
\begin{CodeInput}
R> resampling_coords <- rsmp("spcv_coords", folds = 5)$instantiate(task)
R> 
R> autoplot(resampling_coords,
+   size = 0.8, fold_id = 1, task = task, crs = 4326) *
+   ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
+   ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
\end{CodeInput}


\begin{center}\includegraphics{paper_files/figure-latex/unnamed-chunk-7-1} \end{center}

\end{CodeChunk}

\hypertarget{leave-location-and-time-out-llot}{%
\subsection{Leave-Location-and-Time-Out
(LLOT)}\label{leave-location-and-time-out-llot}}

Leave-Location-and-Time-Out from packge \pkg{CAST} is a spatiotemporal
resampling method. It requires both a spatial and a temporal variable
which are used to to separate observations in a multi-dimensional space.

In this example the \texttt{cookfarm} dataset is used because it
contains a temporal variable (``Date'') which is not present in dataset
\texttt{ecuador}.

The visualization is done in a dynamic way via \pkg{plotly} to visualize
the both temporal and spatial dimensions.

\begin{CodeChunk}
\begin{CodeInput}
R> task_spt = tsk("cookfarm")
R> resampling_cstf <- rsmp("sptcv_cstf",
+   folds = 5,
+   time_var = "Date", space_var = "SOURCEID")
R> 
R> autoplot(resampling_cstf,
+   fold_id = 2, task = task_spt, crs = 4326, static_image = TRUE,
+   file = "plot.pdf") *
+   ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
+   ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
\end{CodeInput}
\begin{CodeOutput}
NULL
\end{CodeOutput}
\end{CodeChunk}

\begin{CodeChunk}


\begin{center}\includegraphics{plot} \end{center}

\end{CodeChunk}

\hypertarget{spatiotemporal-clustering-cluto}{%
\subsection{Spatiotemporal Clustering
(Cluto)}\label{spatiotemporal-clustering-cluto}}

\begin{table}[h]
    \centering
    \caption[t]{Spatiotemporal resampling methods, ordered alphabetically by class name (Notation column).}
    \begingroup
    \begin{tabular}{llll}
        \\
        Literature                  & Package          & Reference          & Notation                    \\
        \toprule
    Spatial Buffering           & \pkg{blockCV}    & \citet{blockCV}    & \texttt{rsmp("spcv\_buffer")} \\
    Spatial Blocking            & \pkg{blockCV}    & \citet{blockCV}    & \texttt{rsmp("spcv\_block")}  \\
    Spatial CV                  & \pkg{sperrorest} & \citet{sperrorest} & \texttt{rsmp("spcv\_cv")}     \\
    Environmental Blocking      & \pkg{blockCV}    & \citet{blockCV}    & \texttt{rsmp("spcv\_env")}    \\
    \midrule
    Leave-Location-and-Time-Out & \pkg{CAST}       & \citet{cast}       & \texttt{rsmp("spcv\_cstf")}   \\
    Spatiotemporal Clustering   & \pkg{skmeans}    & \citet{cluto}      & \texttt{rsmp("spcv\_cluto")}
    \end{tabular}
    \endgroup\label{tab:sptcv-methods}
\end{table}

\hypertarget{section}{%
\subsection{}\label{section}}

\hypertarget{visualization-of-spatiotemporal-partitions}{%
\section{Visualization of Spatiotemporal
Partitions}\label{visualization-of-spatiotemporal-partitions}}

Every partitioning method in
\href{https://mlr3spatiotempcv.mlr-org.com}{mlr3spatiotempcv} comes with
a generic \texttt{plot()} method to visualize the created groups. In a
2D space this happens via \href{https://ggplot2.tidyverse.org}{ggplot2}
\citep{ggplot2} while for spatiotemporal methods 3D visualizations via
\href{https://github.com/ropensci/plotly}{plotly} \citep{plotly} are
created.

\begin{CodeChunk}
\begin{CodeInput}
R> autoplot(resampling_sp, task, fold_id = c(1:4)) *
+   ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
+   ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
\end{CodeInput}
\begin{CodeOutput}
CRS not set, transforming to WGS84 (EPSG: 4326).
CRS not set, transforming to WGS84 (EPSG: 4326).
CRS not set, transforming to WGS84 (EPSG: 4326).
CRS not set, transforming to WGS84 (EPSG: 4326).
\end{CodeOutput}
\begin{figure}[!b]

{\centering \includegraphics{paper_files/figure-latex/vis-spcv-1} 

}

\caption[Visualization of spatial partitioning]{Visualization of spatial partitioning}\label{fig:vis-spcv}
\end{figure}
\end{CodeChunk}

\hfill\break

Unless specified by the user, the coordinate reference system (CRS)
defaults to EPSG code 4326 (WGS84). This is because a lat/lon based CRS
is better suited for plotting purposes than a Mercator (UTM) one. Note
that setting the correct CRS for the given data \emph{during
construction} is very important. Even though EPSG 4326 is a good
fallback and often used for visualization purposes, spatial offsets of
up to multiple meters may occur if the wrong CRS was passed initially.

This example used an already created task via the convenience function
\texttt{tsk()}. In practice however, one needs to create a
spatiotemporal task via \texttt{TaskClassifST()}/\texttt{TaskRegrST()}
and set the \texttt{crs} argument.

The spatial grouping of the k-means based approach above (Figure 1)
contrasts visually very well compared to the NSpCV (random) partitioning
(Figure 2):

\begin{CodeChunk}
\begin{CodeInput}
R> autoplot(resampling_nsp, task, fold_id = c(1:4), crs = 4326) *
+   ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
+   ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
\end{CodeInput}
\begin{figure}[!b]

{\centering \includegraphics{paper_files/figure-latex/vis-nspcv-1} 

}

\caption[Visualization of random partitioning]{Visualization of random partitioning}\label{fig:vis-nspcv}
\end{figure}
\end{CodeChunk}

\hypertarget{choosing-a-resampling-method}{%
\section{Choosing a Resampling
Method}\label{choosing-a-resampling-method}}

While the example used the \texttt{"spcv\_coords"} method, this does not
mean that this method is the best or only method suitable for this task.
Even though this method is quite popular, it was mainly chosen because
of the clear visual grouping differences compared to random
partitioning.

In fact, most often multiple spatial partitioning methods can be used
for a dataset. It is recommended (required) that users familiarize
themselves with each implemented method and decide which method to
choose based on the specific characteristics of the dataset. For almost
all methods implemented in
\href{https://mlr3spatiotempcv.mlr-org.com}{mlr3spatiotempcv}, there is
a scientific publication describing the strengths and weaknesses of the
respective approach (either linked in the help file of
\href{https://mlr3spatiotempcv.mlr-org.com}{mlr3spatiotempcv} or its
respective dependency packages).

In the example above, a cross-validation without hyperparameter tuning
was shown. If a nested CV is desired, it is recommended to use the same
spatial partitioning method for the inner loop (= tuning level). See
\citet{schratz2019} for more details and chapter 11 of
\href{https://geocompr.robinlovelace.net/spatial-cv.html}{Geocomputation
with R} \citep{lovelace2019}.

A list of all implemented methods in
\href{https://mlr3spatiotempcv.mlr-org.com}{mlr3spatiotempcv} can be
found in the
\href{https://mlr3spatiotempcv.mlr-org.com/articles/mlr3spatiotempcv.html}{Getting
Started} vignette of the package.

\renewcommand\refname{References}
\bibliography{paper.bib}


\end{document}
