---
documentclass: jss
author:
  - name: Patrick Schratz
    affiliation: 'Friedrich-Schiller-University Jena \AND'
    # affiliaton2: 'Ludwig-Maximilians-University Munich'
    # use this syntax to add text on several lines
    address: |
      | Faculty of Chemistry and Earth Sciences
      | Department of Geography
      | GIScience group
    email: \email{patrick.schratz@uni-jena.de}
  - name: Marc Becker
    affiliation: 'Ludwig-Maximilians-University Munich'
    address: |
      Department of Statistics
      Statistical Learning and Data Science group
    # To add another line, use \AND at the end of the previous one as above
  - name: Michel Lang
    affiliation: TU Dortmund University
    address: |
      | Faculty of Statistics
title:
  formatted: "\\pkg{mlr3spatiotempcv}: Spatiotemporal Resampling Methods for \\pkg{mlr3}"
  # If you use tex in the formatted title, also supply version without
  plain:     "mlr3spatiotempcv: Spatiotemporal Resampling Methods for mlr3"
  # For running headers, if needed
  # short:     "\\pkg{foo}: A Capitalized Title"
abstract: >
  The R package [mlr3spatiotempcv](https://mlr3spatiotempcv.mlr-org.com) is an extension package of the machine learning framework [mlr3](https://mlr3.mlr-org.com) [@mlr3].
  It adds support for spatiotemporal resampling methods and respective visualization methods.
  Spatiotemporal resampling methods are needed to account for the existence of different autocorrelation types (spatial autocorrelation (SAC), temporal autocorrelation (TAC) or spatio-temporal autocorrelation (STAC)) in datasets.
  These autocorrelation types cause biased performance estimates of varying magnitude in cross-validation when ignored.
  At the time of writing, various R packages implementing different spatiotemporal partitioning strategies exist: CAST [@cast], blockCV [@blockCV] or sperrorest [@sperrorest].
  There are some resampling methods used in scientific studies for which the source code is either not available or a different programming language has been used [@roberts2017; @pohjankukka2017]

  The goal of [mlr3spatiotempcv](https://mlr3spatiotempcv.mlr-org.com) is to gather the available spatiotemporal resampling methods in R and make them available to users through a simplified and generic interface.
  The latter is made possible by integrating the package directly into the [mlr3](https://mlr3.mlr-org.com) machine learning framework.
  This simplifies the step of integrating package specific syntax into an overarching machine learning pipeline.
  The hope is that the availability of such a package encourages researchers to more often apply spatiotemporal resampling methods in scientific case studies.
keywords:
  # at least one keyword must be supplied
  formatted: [resampling, machine learning, autocorrelation, spatial, temporal, "\\proglang{R}"]
  plain:     [resampling, machine learning, autocorrelation, spatial, temporal, R]
preamble: >
  \usepackage{amsmath}
  \usepackage{booktabs}
  \usepackage{longtable}
tables: true
bibliography: paper.bib
output: rticles::jss_article
---

# Introduction

Data which includes spatial or temporal information requires special treatment in machine learning; similar to cost-sensitive, functional, multilabel, ordinal or survival datasets [@mlr3book].
In contrast to non-spatial/non-temporal data, observations inherit a natural grouping, either in space or time or in both space and time [@legendre1993].
This grouping causes observations to be autocorrelated, either in space (spatial autocorrelation (SAC)), time (temporal autocorrelation (TAC)) or both space and time (spatiotemporal autocorrelation (STAC)).
For simplicity, the acronym STAC is used as a generic term in the following discussion for all the different characteristics introduced above.

## Spatiotemporal Autocorrelation in Statistical/Machine Learning

The overarching problem is that STAC violates the assumption that the observations in the train and test datasets are independent [@hastie2001].
If this assumption is violated, the reliability of the resulting performance estimates, for example retrieved via cross-validation, is decreased.
The magnitude of this decrease is linked to the magnitude of STAC in the dataset, which cannot be determined easily.

One approach to account for the existence of STAC is to use dedicated resampling methods.
[mlr3spatiotempcv](https://mlr3spatiotempcv.mlr-org.com) provides access to the most frequently used spatiotemporal resampling methods.
The following example, which uses the [ecuador](https://mlr3spatiotempcv.mlr-org.com/reference/mlr_tasks_ecuador.html) dataset created by [Jannes Muenchow](https://scholar.google.com/citations?user=Slq94Y4AAAAJ&hl=de&authuser=1&oi=ao), showcases how a spatial dataset can be used to retrieve a bias-reduced performance estimate of a learner.

This dataset contains information on the occurrence of landslides (binary) in the Andes of Southern Ecuador.
The landslides were mapped from aerial photos taken in 2000.
The dataset is well suited to serve as an example because it is relatively small and, of course, due to the spatial nature of the observations.
Please refer to @muenchow2012 for a detailed description of the dataset.

To account for the spatial autocorrelation probably present in the landslide data, we will make use of one of the most used spatial partitioning methods, a cluster-based $k$-means grouping [@sperrorest], (`"spcv_coords"` in [mlr3spatiotempcv](https://mlr3spatiotempcv.mlr-org.com)).
This method performs a clustering in 2D space which contrasts with the commonly used random partitioning for non-spatial data.
The grouping has the effect that train and test data are more separated in space than they would be by conducting a random partitioning, thereby reducing the effect of STAC.

By contrast, when using the classical random partitioning approach with spatial data, train and test observations would be located side-by-side across the full study area (a visual example is provided further below).
This leads to a high similarity between train and test sets, resulting in "better" but over-optimistic performance estimates in every fold of a CV compared to the Spatial CV (SpCV) approach.
However, these low error rates are mainly caused due to the STAC in the observations and the lack of appropriate partitioning methods and not by the power of the fitted model.

Rephrased: the higher performance results in a non-spatial CV scenario should not be relied on or used for reporting.
The positive bias in these results is substantial and the actual performance of the model is nowhere near this result.
Results from a SpCV are not unbiased but are closer in reflecting the actual performance of the learner on unknown datasets.

## Motivation

In the last years awareness for spatiotemporal autocorrelation in ML tasks has grown [@pohjankukka2017; @roberts2017].
Subsequently, scientists started writing code to account for the issue in their studies.
With R being one of the most used languages with respect to modeling/statistics and academia in general, R packages were developed aiming to simplify the data splitting with respect to methods able to account for spatial autocorrelation [@cast, @blockCV].
FIXME: adds refs
This is a typical process for the R community as writing R packages has been made relatively straightforward in recent years thanks to efforts from various people/organizations such as Bioconductor, CRAN, ropensci or the tidyverse [@cran, @ropensci, @tidyverse]
Also the effort of bundling code into a defined package structure makes it easier for others to re-use it, which is a good effort towards reproducible science.

The downside of this culture is that "island solutions" are being created, i.e. small packages which serve a particular (sometimes very niche) use case.
Usually the "Do one thing and do it well" UNIX philosophy is widely known and used in practice [@raymond2003art].
However, the issue with R packages is that not every package is necessarily easily compatiable with other ones due to differing input and returns objects, making it problematic to write a clean and tidy workflow.
Also many R packages are written by single persons which not necessarly have a complete overview over existing implementations.
These points may lead to the following possible issues in practice:

- Different syntax.
- Support for only some predictor types (e.g. numeric and factor features but no ordered factors).
- Different return values.
- Different namings for the same method.
- Unclear longterm maintenance.

These points add substantial overhead and/or reproducibility issues for anyone who wants to make use of the provided implementations within their studies.
\pkg{mlr3spatiotempcv} aims to provide a solution for some of the points outlined above by wrapping all spatiotemporal resampling methods available in \proglang{R} packages.
By embedding the package within the \pkg{mlr3} ecosystem and following its unified syntax and scalable approach, \pkg{mlr3spatiotempcv} aims to provide future users longterm support for spatiotemporal partitioning methods in R.

## The mlr3 ecosystem

The \pkg{mlr3} R package and its extensions packages form the \pkg{mlr3} machine learning ecosystem [@mlr3].
\pkg{mlr3} aims to wrap many algorithms available in R to enforce a consistent interface for such.
This adds the ability for simplified benchmarking, visualization and further model evaluation regardless of the chosen algorithm.

\pkg{mlr3spatiotempcv} complements this philosophy by aiming to apply the same standards for spatiotemporal resampling methods.

# Comparing Spatial and Non-Spatial Resampling

To introduce the effect of spatial autocorrelation in modeling, a spatial and non-spatial CV using \pkg{mlr3spatiotempcv} will be shown in the following.
For simplicity, one of the most used methods (spatial k-means clustering after @sperrorest) will be used.
Individual methods are discussed in FIXME.

The performance of a simple classification tree (`"classif.ranger"`) is evaluated on a random repeated cross-validation (`"repeated_cv"`) with four folds and two repetitions.
In reality, more fold (between five and ten) and a higher number of repetitions should be used.
The chosen evaluation measure is the "Area Under the ROC Curve" (`"classif.auc"`) which is a common evaluation measure for binary responses.
The CV will be executed twice with the only difference being the use of a spatial resampling object (initialized with `rsmp("repeated_spcv_coords"`) instead of a non-spatial one (`rsmp("repeated_cv"`).

## Data Preparation

The following code chunk first loads all necessary R packages and sets a low verbosity for this example.
A seed is set for deterministic execution.

Next the mlr3 task `"ecuador"`, which is included in \pkg{mlr3spatiotempcv}, is loaded via `tsk()`.
This function is a convenience wrapper around the underlying R6 construction method for a spatiotemporal classification task (`mlr3spatiotempcv::TaskClassifST$new()`).

Last, the random forest learner (`lrn("classif.ranger")`) is initialized with default hyperparameters and the prediction type set to `"probability"` due to the binary response variable.
A set of commonly used learners is available in \pkg{mlr3learners} [@mlr3learners], including the random forest implementation after @ranger.

By setting the logging threshold, which can be controlled via the \pkg{lgr} package [@lgr], to `"warn"`, verbosity is reduced to keep the example tidy.

```{r setup, echo=FALSE}
# important for correct figure placement
# see https://stackoverflow.com/a/49395389/4185785
knitr::knit_hooks$set(plot = function(x, options) {
  knitr::hook_plot_tex(x, options)
})
knitr::opts_chunk$set(cache = FALSE)
```

```{r prepare, cache=FALSE}
library("mlr3")
library("mlr3spatiotempcv")
library("mlr3learners")
set.seed(42)

# be less verbose
lgr::get_logger("bbotk")$set_threshold("warn")
lgr::get_logger("mlr3")$set_threshold("warn")

task <- tsk("ecuador")

learner <- lrn("classif.ranger", predict_type = "prob")
```

### Non-Spatial Cross-Validation

```{r rr-nspcv, cache=FALSE}
resampling_nsp <- rsmp("repeated_cv", folds = 4, repeats = 2)
rr_nsp <- resample(
  task = task, learner = learner,
  resampling = resampling_nsp
)

rr_nsp$aggregate(measures = msr("classif.auc"))
```

## Spatial Cross-Validation

```{r rr-spcv, cache=FALSE}
resampling_sp <- rsmp("repeated_spcv_coords", folds = 4, repeats = 2)
rr_sp <- resample(
  task = task, learner = learner,
  resampling = resampling_sp
)

rr_sp$aggregate(measures = msr("classif.auc"))
```

Here, the estimated AUC using Non-Spatial Cross-Validation (NSpCV) is around 0.15 better compared to the Spatial Cross-Validation (SpCV).
The better performance score results from over-optimism in the estimation with NSpCV.
The actual predictive performance on new data is much more realistically reflected by the performance estimated via SpCV.
The magnitude of this difference is variable as it depends on the dataset, the magnitude of STAC and the learner itself.
Algorithms with a higher tendency of overfitting to the training set will have a large spread in such scenarios.

# Spatiotemporal Partitioning Methods

At the time of writing, the following spatiotemporal resampling methods (FIXME ref table) were available across different R packages.
This list might increase over time and it is recommended to consult the homepage of \pkg{mlr3spatiotempcv} for an up-to-date list.

A low-level introduction is given for every method included at this point of this article.
For a discussion with respect to usage see section FIXME.

## Spatial Buffering

The "buffering" method from the \pkg{blockCV} package is conceptually similar to a leave-one-out (LOO) cross-validation approach [@rest2014, @blockCV].
To reduce the similarity between train and test, a circular buffer around the observations representing the test set is drawn.
Within this buffer zone, all observations are removed from the training set, thereby reducing the similarity between train and test set and subsequently the influence of SAC.

By default, the method considers all points for train/test creation.
In an ecological context, this equals to the assumption of having *presence/absence* data for binary response variables.
This means all non-presence values in the response variable are assumed to be confirmed absence values.

The implementation also comes with support for *presence/background* data for binary responses.
In this scenario, only the presence values are considered validated.
All other response observations are assumed to be absent without a proof for this assumption.
When setting argument `spDataType = "PB"`, the method only considers the *presence* observations in a CV scenario.
Background data is used for training the model by default unless argument `addBG = FALSE` is set for which only *presence* values not falling within the buffer zone of the respective fold are used for model training.

Due to its similarity to a LOO CV, this method will result in as many train/test evaluations as observations are present.
In the example below, a buffer zone of 1000 m is used and the first fold shown is plotted.

```{r}
resampling_buffer <- rsmp("spcv_buffer", theRange = 1000)

autoplot(resampling_buffer, size = 0.7, task = task, fold_id = 1, crs = 4326) *
  ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
  ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
```

<!-- TODO: Discuss issues setting a sensible range value -->

## Spatial Blocking

"Spatial Blocking" aims to create homogeneous blocks across the study area dividing observations into different zones of which each represents a partition.
The way how these folds are created can be manifold: 

1. Supplying a numeric value in meters via argument `theRange` will create a quadratic block pattern across the study area following either a random (`selection = "random"`), systematic (`selection = "systematic"`) or checkerboard structure (`selection = "checkerboard"`).

```{r}
resampling_block_random <- rsmp("spcv_block", range = 500, folds = 5)

autoplot(resampling_block_random,
  size = 0.8, fold_id = 1,
  task = task, crs = 4326, show_blocks = TRUE) *
  ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
  ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
```


## Spatial CV

## Environmental Blocking

## Leave-Location-and-Time-Out (LLOT)

## Spatiotemporal Clustering (Cluto)

\begin{table}[h]
	\centering
	\caption[t]{Spatiotemporal resampling methods, ordered alphabetically by class name (Notation column).}
	\begingroup
	\begin{tabular}{llll}
		\\
		Literature                  & Package          & Reference          & Notation                    \\
		\toprule
    Spatial Buffering           & \pkg{blockCV}    & \citet{blockCV}    & \texttt{rsmp("spcv\_buffer")} \\
    Spatial Blocking            & \pkg{blockCV}    & \citet{blockCV}    & \texttt{rsmp("spcv\_block")}  \\
    Spatial CV                  & \pkg{sperrorest} & \citet{sperrorest} & \texttt{rsmp("spcv\_cv")}     \\
    Environmental Blocking      & \pkg{blockCV}    & \citet{blockCV}    & \texttt{rsmp("spcv\_env")}    \\
    \midrule
    Leave-Location-and-Time-Out & \pkg{CAST}       & \citet{cast}       & \texttt{rsmp("spcv\_cstf")}   \\
    Spatiotemporal Clustering   & \pkg{skmeans}    & \citet{cluto}      & \texttt{rsmp("spcv\_cluto")}
	\end{tabular}
	\endgroup\label{tab:sptcv-methods}
\end{table}

##

# Visualization of Spatiotemporal Partitions

Every partitioning method in [mlr3spatiotempcv](https://mlr3spatiotempcv.mlr-org.com) comes with a generic `plot()` method to visualize the created groups.
In a 2D space this happens via [ggplot2](https://ggplot2.tidyverse.org) [@ggplot2] while for spatiotemporal methods 3D visualizations via [plotly](https://github.com/ropensci/plotly) [@plotly] are created.

```{r vis-spcv, fig.cap="Visualization of spatial partitioning", fig.pos="!b", fig.height=6, fig.width=8}
autoplot(resampling_sp, task, fold_id = c(1:4)) *
  ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
  ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
```
\

Unless specified by the user, the coordinate reference system (CRS) defaults to EPSG code 4326 (WGS84).
This is because a lat/lon based CRS is better suited for plotting purposes than a Mercator (UTM) one.
Note that setting the correct CRS for the given data *during construction* is very important.
Even though EPSG 4326 is a good fallback and often used for visualization purposes, spatial offsets of up to multiple meters may occur if the wrong CRS was passed initially.

This example used an already created task via the convenience function `tsk()`.
In practice however, one needs to create a spatiotemporal task via `TaskClassifST()`/`TaskRegrST()` and set the `crs` argument.

The spatial grouping of the k-means based approach above (Figure 1) contrasts visually very well compared to the NSpCV (random) partitioning (Figure 2):

```{r vis-nspcv, fig.cap="Visualization of random partitioning", fig.pos="!b", fig.height=6, fig.width=8}
autoplot(resampling_nsp, task, fold_id = c(1:4), crs = 4326) *
  ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
  ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
```

# Choosing a Resampling Method

While the example used the `"spcv_coords"` method, this does not mean that this method is the best or only method suitable for this task.
Even though this method is quite popular, it was mainly chosen because of the clear visual grouping differences compared to random partitioning.

In fact, most often multiple spatial partitioning methods can be used for a dataset.
It is recommended (required) that users familiarize themselves with each implemented method and decide which method to choose based on the specific characteristics of the dataset.
For almost all methods implemented in [mlr3spatiotempcv](https://mlr3spatiotempcv.mlr-org.com), there is a scientific publication describing the strengths and weaknesses of the respective approach (either linked in the help file of [mlr3spatiotempcv](https://mlr3spatiotempcv.mlr-org.com) or its respective dependency packages).

In the example above, a cross-validation without hyperparameter tuning was shown.
If a nested CV is desired, it is recommended to use the same spatial partitioning method for the inner loop (= tuning level).
See @schratz2019 for more details and chapter 11 of [Geocomputation with R](https://geocompr.robinlovelace.net/spatial-cv.html) [@lovelace2019].

A list of all implemented methods in [mlr3spatiotempcv](https://mlr3spatiotempcv.mlr-org.com) can be found in the [Getting Started](https://mlr3spatiotempcv.mlr-org.com/articles/mlr3spatiotempcv.html) vignette of the package.

# References
