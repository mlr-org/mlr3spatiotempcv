---
documentclass: jss
author:
  - name: Patrick Schratz
    affiliation: 'Friedrich-Schiller-University Jena \AND'
    # affiliaton2: 'Ludwig-Maximilians-University Munich'
    # use this syntax to add text on several lines
    address: |
      | Faculty of Chemistry and Earth Sciences
      | Department of Geography
      | GIScience group
    email: \email{patrick.schratz@uni-jena.de}
  - name: Marc Becker
    affiliation: 'Ludwig-Maximilians-University Munich'
    address: |
      Department of Statistics
      Statistical Learning and Data Science group
    # To add another line, use \AND at the end of the previous one as above
  - name: Michel Lang
    affiliation: TU Dortmund University
    address: |
      | Faculty of Statistics
title:
  formatted: "\\pkg{mlr3spatiotempcv}: Spatiotemporal Resampling Methods for \\pkg{mlr3}"
  # If you use tex in the formatted title, also supply version without
  plain:     "mlr3spatiotempcv: Spatiotemporal Resampling Methods for mlr3"
  # For running headers, if needed
  # short:     "\\pkg{foo}: A Capitalized Title"
abstract: >
  The R package [mlr3spatiotempcv](https://mlr3spatiotempcv.mlr-org.com) is an extension package of the machine learning framework [mlr3](https://mlr3.mlr-org.com) [@mlr3].
  It adds support for spatiotemporal resampling methods and respective visualization methods.
  Spatiotemporal resampling methods are needed to account for the existence of different autocorrelation types (spatial autocorrelation (SAC), temporal autocorrelation (TAC) or spatio-temporal autocorrelation (STAC)) in datasets.
  These autocorrelation types cause biased performance estimates of varying magnitude in cross-validation when ignored.
  At the time of writing, various R packages implementing different spatiotemporal partitioning strategies exist: CAST [@cast], blockCV [@blockCV] or sperrorest [@sperrorest].
  There are some resampling methods used in scientific studies for which the source code is either not available or a different programming language has been used [@roberts2017; @pohjankukka2017]

  The goal of [mlr3spatiotempcv](https://mlr3spatiotempcv.mlr-org.com) is to gather the available spatiotemporal resampling methods in R and make them available to users through a simplified and generic interface.
  The latter is made possible by integrating the package directly into the [mlr3](https://mlr3.mlr-org.com) machine learning framework.
  This simplifies the step of integrating package specific syntax into an overarching machine learning pipeline.
  The hope is that the availability of such a package encourages researchers to more often apply spatiotemporal resampling methods in scientific case studies.
keywords:
  # at least one keyword must be supplied
  formatted: [resampling, machine learning, autocorrelation, spatial, temporal, "\\proglang{R}"]
  plain:     [resampling, machine learning, autocorrelation, spatial, temporal, R]
preamble: >
  \usepackage{amsmath}
  \usepackage{booktabs}
  \usepackage{longtable}
tables: true
bibliography: paper.bib
# output: rticles::jss_article
output:
  bookdown::pdf_book:
    base_format: rticles::jss_article
---

```{r setup, echo=FALSE}
# important for correct figure placement
# see https://stackoverflow.com/a/49395389/4185785
knitr::knit_hooks$set(plot = function(x, options) {
  knitr::hook_plot_tex(x, options)
})
# knitr::opts_chunk$set(cache = FALSE)
```

# Introduction

Data which includes spatial or temporal information requires special treatment in machine learning; similar to cost-sensitive, functional, multilabel, ordinal or survival datasets [@mlr3book].
In contrast to non-spatial/non-temporal data, observations inherit a natural grouping, either in space or time or in both space and time [@legendre1993].
This grouping causes observations to be autocorrelated, either in space (spatial autocorrelation (SAC)), time (temporal autocorrelation (TAC)) or both space and time (spatiotemporal autocorrelation (STAC)).
For simplicity, the acronym STAC is used as a generic term in the following discussion for all the different characteristics introduced above.

## Spatiotemporal Autocorrelation in Statistical/Machine Learning

The overarching problem is that STAC violates the assumption that the observations in the train and test datasets are independent [@hastie2001].
If this assumption is violated, the reliability of the resulting performance estimates, for example retrieved via cross-validation, is decreased.
The magnitude of this decrease is linked to the magnitude of STAC in the dataset, which cannot be determined easily.

One approach to account for the existence of STAC is to use dedicated resampling methods.
[mlr3spatiotempcv](https://mlr3spatiotempcv.mlr-org.com) provides access to the most frequently used spatiotemporal resampling methods.
The following example, which uses the [ecuador](https://mlr3spatiotempcv.mlr-org.com/reference/mlr_tasks_ecuador.html) dataset created by [Jannes Muenchow](https://scholar.google.com/citations?user=Slq94Y4AAAAJ&hl=de&authuser=1&oi=ao), showcases how a spatial dataset can be used to retrieve a bias-reduced performance estimate of a learner.

This dataset contains information on the occurrence of landslides (binary) in the Andes of Southern Ecuador.
The landslides were mapped from aerial photos taken in 2000.
The dataset is well suited to serve as an example because it is relatively small and, of course, due to the spatial nature of the observations.
Please refer to @muenchow2012 for a detailed description of the dataset.

To account for the spatial autocorrelation probably present in the landslide data, we will make use of one of the most used spatial partitioning methods, a cluster-based $k$-means grouping [@sperrorest], (`"spcv_coords"` in [mlr3spatiotempcv](https://mlr3spatiotempcv.mlr-org.com)).
This method performs a clustering in 2D space which contrasts with the commonly used random partitioning for non-spatial data.
The grouping has the effect that train and test data are more separated in space than they would be by conducting a random partitioning, thereby reducing the effect of STAC.

By contrast, when using the classical random partitioning approach with spatial data, train and test observations would be located side-by-side across the full study area (a visual example is provided further below).
This leads to a high similarity between train and test sets, resulting in "better" but over-optimistic performance estimates in every fold of a CV compared to the Spatial CV (SpCV) approach.
However, these low error rates are mainly caused due to the STAC in the observations and the lack of appropriate partitioning methods and not by the power of the fitted model.

Rephrased: the higher performance results in a non-spatial CV scenario should not be relied on or used for reporting.
The positive bias in these results is substantial and the actual performance of the model is nowhere near this result.
Results from a SpCV are not unbiased but are closer in reflecting the actual performance of the learner on unknown datasets.

## Motivation

In the last years awareness for spatiotemporal autocorrelation in ML tasks has grown [@pohjankukka2017; @roberts2017].
Subsequently, scientists started writing code to account for the issue in their studies.
With R being one of the most used languages with respect to modeling/statistics and academia in general, R packages were developed aiming to simplify the data splitting with respect to methods able to account for spatial autocorrelation [@cast, @blockCV].
FIXME: adds refs
This is a typical process for the R community as writing R packages has been made relatively straightforward in recent years thanks to efforts from various people/organizations such as Bioconductor, CRAN, ropensci or the tidyverse [@cran, @ropensci, @tidyverse]
Also the effort of bundling code into a defined package structure makes it easier for others to re-use it, which is a good effort towards reproducible science.

The downside of this culture is that "island solutions" are being created, i.e. small packages which serve a particular (sometimes very niche) use case.
Usually the "Do one thing and do it well" UNIX philosophy is widely known and used in practice [@raymond2003art].
However, the issue with R packages is that not every package is necessarily easily compatiable with other ones due to differing input and returns objects, making it problematic to write a clean and tidy workflow.
Also many R packages are written by single persons which not necessarly have a complete overview over existing implementations.
These points may lead to the following possible issues in practice:

- Different syntax.
- Support for only some predictor types (e.g. numeric and factor features but no ordered factors).
- Different return values.
- Different namings for the same method.
- Unclear longterm maintenance.

These points add substantial overhead and/or reproducibility issues for anyone who wants to make use of the provided implementations within their studies.
\pkg{mlr3spatiotempcv} aims to provide a solution for some of the points outlined above by wrapping all spatiotemporal resampling methods available in \proglang{R} packages.
By embedding the package within the \pkg{mlr3} ecosystem and following its unified syntax and scalable approach, \pkg{mlr3spatiotempcv} aims to provide future users longterm support for spatiotemporal partitioning methods in R.

## The mlr3 ecosystem

The \pkg{mlr3} R package and its extensions packages form the \pkg{mlr3} machine learning ecosystem [@mlr3].
\pkg{mlr3} aims to wrap many algorithms available in R to enforce a consistent interface for such.
This adds the ability for simplified benchmarking, visualization and further model evaluation regardless of the chosen algorithm.

\pkg{mlr3spatiotempcv} complements this philosophy by aiming to apply the same standards for spatiotemporal resampling methods.

# Visualization of Spatiotemporal Partitions

Every partitioning method in [mlr3spatiotempcv](https://mlr3spatiotempcv.mlr-org.com) comes with a generic `plot()` method to visualize the created groups.
In a 2D space this happens via [ggplot2](https://ggplot2.tidyverse.org) [@ggplot2] while for spatiotemporal methods 3D visualizations are created via [plotly](https://github.com/ropensci/plotly) [@plotly].

Unless specified by the user, the coordinate reference system (CRS) defaults to EPSG code 4326 (WGS84).
This is because a lat/lon based CRS is better suited for plotting purposes than a Mercator (UTM) one.
Note that setting the correct CRS for the given data *during construction* is very important.
Even though EPSG 4326 is a good fallback and often used for visualization purposes, spatial offsets of up to multiple meters may occur if the wrong CRS was passed initially.

Note: The following example uses a built-in task via function `tsk()`.
In practice however, one needs to create a spatiotemporal task first via `TaskClassifST()`/`TaskRegrST()`..

The spatial grouping of the k-means based approach (`"spcv_coords"`) (Fig.\@ref(fig:vis-spcv)) contrasts visually very well to the NSpCV (random) partitioning (Fig.\@ref(fig:vis-nspcv)).

```{r vis-spcv, fig.cap="Visualization of spatial partitioning", fig.pos="t!", fig.height=6, fig.width=8, cache=TRUE}
library(mlr3)
library(mlr3spatiotempcv)

# be less verbose
lgr::get_logger("bbotk")$set_threshold("warn")
lgr::get_logger("mlr3")$set_threshold("warn")

set.seed(42)

task = tsk("ecuador")

resampling_sp <- rsmp("repeated_spcv_coords", folds = 4, repeats = 2)
resampling_sp$instantiate(task)

autoplot(resampling_sp, task, fold_id = c(1:2), crs = 4326, size = 0.8) *
  ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
  ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
```

```{r vis-nspcv, fig.cap="Visualization of random partitioning", fig.pos="t!", fig.height=6, fig.width=8, cache=T}
resampling_nsp <- rsmp("repeated_cv", folds = 4, repeats = 2)
resampling_nsp$instantiate(task)

autoplot(resampling_nsp, task, fold_id = c(1:2), crs = 4326, size = 0.8) *
  ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
  ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
```

# Spatiotemporal Partitioning Methods

At the time of writing, the following spatiotemporal resampling methods (Table \@ref(tab:sptcv-methods)) were available across different R packages.
This list might increase over time and it is recommended to consult the homepage of \pkg{mlr3spatiotempcv} for an up-to-date list.

A low-level introduction is given for every method included at this point of this article.
For a discussion with respect to usage see section FIXME.

## Spatial Buffering

The "buffering" method from the \pkg{blockCV} package is conceptually similar to a leave-one-out (LOO) cross-validation approach [@rest2014, @blockCV].
To reduce the similarity between train and test, a circular buffer around the observations representing the test set is drawn.
Within this buffer zone, all observations are removed from the training set, thereby reducing the similarity between train and test set and subsequently the influence of SAC.

By default, the method considers all points for train/test creation.
In an ecological context, this equals to the assumption of having *presence/absence* data for binary response variables.
This means all non-presence values in the response variable are assumed to be confirmed absence values.

The implementation also comes with support for *presence/background* data for binary responses.
In this scenario, only the presence values are considered validated.
All other response observations are assumed to be absent without a proof for this assumption.
When setting argument `spDataType = "PB"`, the method only considers the *presence* observations in a CV scenario.
Background data is used for training the model by default unless argument `addBG = FALSE` is set for which only *presence* values not falling within the buffer zone of the respective fold are used for model training.

Due to its similarity to a LOO CV, this method will result in as many train/test evaluations as observations are present.
In the example below, a buffer zone of 1000 m is used and the first fold shown is plotted (Fig.\@ref(fig:buffer))).

```{r buffer, fig.cap="Visualization of 'Spatial buffering' method.", out.width="50%", cache=T}
resampling_buffer <- rsmp("spcv_buffer", theRange = 1000)
resampling_buffer$instantiate(task)

autoplot(resampling_buffer,
  size = 0.8, task = task, fold_id = 1, crs = 4326) *
  ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
  ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
```

<!-- TODO: Discuss issues setting a sensible range value -->

## Spatial Blocking

"Spatial Blocking" (\pkg{blockCV} package) creates homogeneous blocks across the study area splitting observations into different zones [@bahn2012a, @wenger2012a].
Then, a number of zones is combined randomly following desired the number of folds.
For example, in a five-fold scenario, the method tries to combines zones to end up with partitions containing around 20\% of all observations.

The way how the blocks are created can be manifold: 

1. Supplying a numeric value in meters via argument `theRange` (named just `range` in {mlr3spatiotempcv}) will create a quadratic block pattern across the study area.
  The aggregation of zones can either be random (default) (`selection = "random"`), systematic (`selection = "systematic"`) or checkerboard structure (`selection = "checkerboard"`).
  
### Option: selection = "random"

```{r block-random, cache = TRUE, fig.cap="Spatial blocking with option `selection = 'random'`.", out.width="50%", fig.pos="h"}
resampling_block_random <- rsmp("spcv_block", range = 1000, folds = 5)

autoplot(resampling_block_random,
  size = 0.8, fold_id = 1, task = task, crs = 4326,
  show_blocks = TRUE, show_labels = TRUE) *
  ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
  ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
```

### Option: selection = "systematic"

Here, aggregation follows the linear count from $1:n_{folds}$ from top to bottom.

```{r block-systematic, cache=TRUE, fig.cap="Spatial blocking with option `selection = 'systematic'`.", out.width="50%", fig.pos="h"}
resampling_block_systematic <- rsmp("spcv_block",
  range = 1000, folds = 5,
  selection = "systematic"
)

autoplot(resampling_block_systematic,
  size = 0.8, fold_id = 1, task = task, crs = 4326,
  show_blocks = TRUE, show_labels = TRUE) *
  ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
  ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
```

### Option: selection = "checkerboard"

This option ignores parameter `range` and always creates two partitions following a "1,2,1,2" pattern.

```{r block-checkerboard, cache=TRUE, fig.cap="Spatial blocking with option `selection = 'checkerboard'`.", out.width="50%", fig.pos="h"}
resampling_block_checkerboard <- rsmp("spcv_block",
  range = 1000, folds = 5,
  selection = "checkerboard")

autoplot(resampling_block_checkerboard,
  size = 0.8, fold_id = 1, task = task, crs = 4326,
  show_blocks = TRUE, show_labels = TRUE) *
  ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
  ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
```

## Environmental Blocking

The last method from the \pkg{blockCV} package, "environmental blocking", makes use of *k-means* clustering [@hartigan1979a] in a possibly multivariate space.
The user can specify a variable via argument `feature` which levels will be used to create clusters.
Hereby, k-means will use Euclidean distance for cluster creation.
Hence, the selected input variables should be of type numeric.
To avoid a potential bias introduced by features with high variance when selecting multiple features, all features are standardized by default.

The following example clusters by feature "distance to forest".

```{r env-1, fig.cap="Environmental blocking using a single predictor.", cache=TRUE, out.width="50%", fig.pos="h"}
resampling_env <- rsmp("spcv_env",
  features = "distdeforest", folds = 5)

autoplot(resampling_env,
  size = 0.8, fold_id = 1, task = task, crs = 4326,
  show_blocks = TRUE, show_labels = TRUE) *
  ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
  ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
```

It is also possible to cluster by multiple features:

```{r env-2, fig.cap="Environmental blocking using multiple predictors.", cache=TRUE, out.width="50%", fig.pos="h"}
resampling_env_multi <- rsmp("spcv_env",
  features = c("distdeforest", "slope"), folds = 5)

autoplot(resampling_env_multi,
  size = 0.8, fold_id = 1, task = task, crs = 4326,
  show_blocks = TRUE, show_labels = TRUE) *
  ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
  ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
```

## Spatial CV

The "Spatial CV" method after [@sperrorest] and implemented in package \pkg{sperrorest} is similar to method "environmental blocking" in that it also uses *k-means* clustering for fold creation.
However, it does not make use of arbitrary features but uses the coordinates of all observations to create clusters in the spatial domain.
This is what lead to the naming of `spcv_coords` in \pkg{mlr3spatiotempcv}.

```{r coords, fig.cap="Method 'Spatial CV' showing a k-means clustering approach based on coordinates.", cache=TRUE, out.width="50%", fig.pos="h"}
resampling_coords <- rsmp("spcv_coords", folds = 5)$instantiate(task)

autoplot(resampling_coords,
  size = 0.8, fold_id = 1, task = task, crs = 4326) *
  ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
  ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
```

## CreateSpacetimeFolds (Cstf)

Leave-Location-and-Time-Out from packge \pkg{CAST} is a spatiotemporal resampling method [@meyer2018a].
It requires both a spatial and a temporal variable which are used to to separate observations in a multi-dimensional space.
It comes with satellite methods named "Leave-time-out" (LTO) and "Leave-location-out" (LLO) which only operatre in a two-dimensional space.

In this example the `cookfarm` dataset is used because it contains a temporal variable ("Date") which is not present in dataset `ecuador`.

Two visualization types are supported: a two-dimensional and a three-dimensional method which can be selected via the logical argument `plot3d`.
The 3D visualization has been implemented via \pkg{plotly}.
Because a dynamic image cannot be included in this manuscript, a static version, which can be generated by setting `static_image = TRUE`, is shown. 

In \pkg{mlr3spatiotempcv} the method is named `"sptcv_cstf"` because the underlying upstream implementation in package \pkg{CAST} is named `CreateSpacetimeFolds()`.

### Leave-Time-Out (LTO)

To better showcase the partitioning of the "Leave-Time-Out" (LTO) method, the temporal variable `Date` was adjusted in this example.

The following code uses the `cookfarm` dataset as the base, modifies to the `Date` variable to contain five unique levels and then creates a spatiotemporal regression task in \pkg{mlr3spatiotempcv} (Fig.\@ref(fig:lto)).

```{r, results='hide', cache=TRUE}
data = cookfarm_sample
data$Date = rep(c(
  "2020-01-01", "2020-02-01", "2020-03-01", "2020-04-01",
  "2020-05-01"), times = 1, each = 100)
b = mlr3::as_data_backend(data)
b$hash = "_mlr3_tasks_cookfarm_"
task_spt = TaskRegrST$new(
  id = "cookfarm", b, target = "PHIHOX",
  extra_args = list(
    coordinate_names = c("x", "y"), coords_as_features = FALSE,
    crs = 26911)
)

resampling_cstf_time = rsmp("sptcv_cstf", folds = 5, time_var = "Date")
resampling_cstf_time$instantiate(task_spt)

autoplot(resampling_cstf_time,
  fold_id = 5, task = task_spt, crs = 4326, plot3D = TRUE
)
```

```{r lto, echo=FALSE, out.width="90%", fig.cap="Three-dimensional visualization of method `sptcv\\_cstf` and sub-method Leave-Time-Out (LTO). To support showcasing the temporal grouping, five folds and five temporal levels in variable `Date` were used in this example.", fig.pos="h"}
knitr::include_graphics("lto.png")
```

### Leave-Location-Out (LLO)

Method "Leave-Location-Out" (LLO) works similar to "Leave-Time-Out" (LTO) in that it operates in a two-dimensional space.
Here, specific locations are left out for forming the partitions while the temporal information is ignored (Fig.\@ref(fig:llo)).

```{r cache=TRUE, results='hide'}
resampling_cstf_loc = rsmp("sptcv_cstf", folds = 5, space_var = "SOURCEID")
resampling_cstf_loc$instantiate(task_spt)

autoplot(resampling_cstf_loc,
  fold_id = 5, task = task_spt, crs = 4326, plot3D = TRUE)
```

```{r llo, echo=FALSE, out.width="90%", fig.cap="Three-dimensional visualization of method 'sptcv\\_cstf' and sub-method 'Leave-Location-Out' (LLO). To support showcasing the spatial grouping, the viewing angle has been adjusted to a view from top. Points are stacked by temporal levels and only points from the same location are chosen to form a partition.", fig.pos="h"}
knitr::include_graphics("llo.png")
```

### Leave-Location-and-Time-Out (LLTO)

The "Leave-Location-and-Time-Out" (LLTO) method combines both "Leave-Time-Out" (LTO) and "Leave-Location-Out" (LLO).
It creates partitions that operate on spatiotemporal clusters to reduce both spatial and temporal autocorrelations.
To achieve this, observations are omitted and only a subset is used.
In the special scenario with five temporal levels and five folds, the train/test split happens only at one temporal level (Fig.\@ref(fig:llto)).

```{r cache=TRUE, results='hide'}
resampling_cstf_time_loc = rsmp("sptcv_cstf",
  folds = 5,
  space_var = "SOURCEID", time_var = "Date")
resampling_cstf_time_loc$instantiate(task_spt)

autoplot(resampling_cstf_time_loc,
  fold_id = 4, task = task_spt, crs = 4326, plot3D = TRUE,
  show_omitted = TRUE)
```

```{r llto, echo=FALSE, out.width="90%", fig.cap="Three-dimensional visualization of method 'sptcv\\_cstf' and sub-method 'Leave-Location-And-Time-Out' (LLTO). The grey points show the points omitted by this method.", cache=TRUE, fig.pos="h"}
knitr::include_graphics("llto.png")
```

## Spatiotemporal Clustering (Cluto)

\begin{table}[h]
	\centering
	\caption[t]{Spatiotemporal resampling methods, ordered alphabetically by class name (Notation column).}
	\begingroup
	\begin{tabular}{llll}
		\\
		Literature                  & Package          & Reference          & Notation                    \\
		\toprule
    Spatial Buffering           & \pkg{blockCV}    & \citet{blockCV}    & \texttt{rsmp("spcv\_buffer")} \\
    Spatial Blocking            & \pkg{blockCV}    & \citet{blockCV}    & \texttt{rsmp("spcv\_block")}  \\
    Spatial CV                  & \pkg{sperrorest} & \citet{sperrorest} & \texttt{rsmp("spcv\_cv")}     \\
    Environmental Blocking      & \pkg{blockCV}    & \citet{blockCV}    & \texttt{rsmp("spcv\_env")}    \\
    \midrule
    Leave-Location-and-Time-Out & \pkg{CAST}       & \citet{cast}       & \texttt{rsmp("spcv\_cstf")}   \\
    Spatiotemporal Clustering   & \pkg{skmeans}    & \citet{cluto}      & \texttt{rsmp("spcv\_cluto")}
	\end{tabular}
	\endgroup\label{tab:sptcv-methods}
\end{table}


# Comparing Spatial and Non-Spatial Resampling

To show the effect of spatial autocorrelation in modeling, a spatial and non-spatial CV using \pkg{mlr3spatiotempcv} will be shown in the following.
For simplicity, one of the most used methods (spatial k-means clustering after @sperrorest) will be used.
Individual methods are discussed in FIXME.

The performance of a simple classification tree (`"classif.ranger"`) is evaluated on a random repeated cross-validation (`"repeated_cv"`) with four folds and two repetitions.
In reality, more fold (between five and ten) and a higher number of repetitions should be used.
The chosen evaluation measure is the "Area Under the ROC Curve" (`"classif.auc"`) which is a common evaluation measure for binary responses.
The CV will be executed twice with the only difference being the use of a spatial resampling object (initialized with `rsmp("repeated_spcv_coords"`) instead of a non-spatial one (`rsmp("repeated_cv"`).

## Data Preparation

The following code chunk first loads all necessary R packages and sets a low verbosity for this example.
A seed is set for deterministic execution.

Next the mlr3 task `"ecuador"`, which is included in \pkg{mlr3spatiotempcv}, is loaded via `tsk()`.
This function is a convenience wrapper around the underlying R6 construction method for a spatiotemporal classification task (`mlr3spatiotempcv::TaskClassifST$new()`).

Next, the random forest learner (`lrn("classif.ranger")`) is initialized with default hyperparameters and the prediction type set to `"probability"` due to the binary response variable.
A set of commonly used learners is available in \pkg{mlr3learners} [@mlr3learners], including the random forest implementation after @ranger.

By setting the logging threshold, which can be controlled via the \pkg{lgr} package [@lgr], to `"warn"`, verbosity is reduced to keep the example tidy.

```{r prepare, cache=TRUE}
library("mlr3")
library("mlr3spatiotempcv")
library("mlr3learners")

task <- tsk("ecuador")

learner <- lrn("classif.ranger", predict_type = "prob")
```

### Non-Spatial Cross-Validation

Here, a four-fold, two times repeated non-spatial resampling structure is constructed and instantianeted via method `$instantiate()`.
Next, the created resampling object `resampling_nsp` is passed to function `resample()` together with the Task and Learner created earlier to execute the cross-validation.

Last, the results from the CV are aggregated using the measure `"classif.auc"`, which is the technical notation for the Area Under the Receivers Operating Curve (AUROC).

```{r rr-nspcv, cache=TRUE, cache.lazy = FALSE}
resampling_nsp <- rsmp("repeated_cv", folds = 4, repeats = 2)
resampling_nsp$instantiate(task)
rr_nsp <- resample(
  task = task, learner = learner,
  resampling = resampling_nsp
)

rr_nsp$aggregate(measures = msr("classif.auc"))
```

## Spatial Cross-Validation

The same approach as for non-spatial resampling is used for spatial resampling, expect the method being `"repeated_spcv_coords"` instead of `"repeated_cv"`.

```{r rr-spcv, cache=TRUE, cache.lazy = FALSE}
resampling_sp <- rsmp("repeated_spcv_coords", folds = 4, repeats = 2)
resampling_sp$instantiate(task)
rr_sp <- resample(
  task = task, learner = learner,
  resampling = resampling_sp
)

rr_sp$aggregate(measures = msr("classif.auc"))
```

The resulting AUC using Non-Spatial Cross-Validation (NSpCV) is around 0.15 better compared to the Spatial Cross-Validation (SpCV).
The better performance score results from over-optimism in the estimation with NSpCV.
The actual predictive performance on new data is much more realistically reflected by the performance estimated via SpCV.
The magnitude of this difference is variable as it depends on the dataset, the magnitude of STAC and the learner itself.
Algorithms with a higher tendency of overfitting to the training set will have a large spread in such scenarios.

# Choosing a Resampling Method

While the example used the `"spcv_coords"` method, this does not mean that this method is the best or only method suitable for this task.
Even though this method is quite popular, it was mainly chosen because of the clear visual grouping differences compared to random partitioning.

In fact, most often multiple spatial partitioning methods can be used for a dataset.
It is recommended (required) that users familiarize themselves with each implemented method and decide which method to choose based on the specific characteristics of the dataset.
For almost all methods implemented in [mlr3spatiotempcv](https://mlr3spatiotempcv.mlr-org.com), there is a scientific publication describing the strengths and weaknesses of the respective approach (either linked in the help file of [mlr3spatiotempcv](https://mlr3spatiotempcv.mlr-org.com) or its respective dependency packages).

In the example above, a cross-validation without hyperparameter tuning was shown.
If a nested CV is desired, it is recommended to use the same spatial partitioning method for the inner loop (= tuning level).
See @schratz2019 for more details and chapter 11 of [Geocomputation with R](https://geocompr.robinlovelace.net/spatial-cv.html) [@lovelace2019].

A list of all implemented methods in [mlr3spatiotempcv](https://mlr3spatiotempcv.mlr-org.com) can be found in the [Getting Started](https://mlr3spatiotempcv.mlr-org.com/articles/mlr3spatiotempcv.html) vignette of the package.

# References
