---
documentclass: jss
author:
  - name: Patrick Schratz
    affiliation: 'Friedrich Schiller University Jena'
    # affiliaton2: 'Ludwig-Maximilians-University Munich'
    # use this syntax to add text on several lines
    address: |
      | Department of Geography
      | Geographic Information Science group
    email: \email{patrick.schratz@uni-jena.de}
  - name: Alexander Brenning
    affiliation: 'Friedrich Schiller University Jena \AND'
    address: |
      | Department of Geography
      | Geographic Information Science group
    email: \email{alexander.brenning@uni-jena.de}
  - name: Marc Becker
    affiliation: 'Ludwig-Maximilians-University Munich'
    address: |
      Department of Statistics
      Statistical Learning and Data Science group
    # To add another line, use \AND at the end of the previous one as above
  - name: Michel Lang
    affiliation: TU Dortmund University
    address: |
      | Faculty of Statistics
title:
  formatted: "\\pkg{mlr3spatiotempcv}: Spatiotemporal resampling methods for machine learning in R with \\pkg{mlr3}"
  # If you use tex in the formatted title, also supply version without
  plain:     "mlr3spatiotempcv: spatiotemporal resampling methods for machine learning in R with mlr3"
  # For running headers, if needed
  # short:     "\\pkg{foo}: A Capitalized Title"
abstract: >
  The R package [mlr3spatiotempcv](https://mlr3spatiotempcv.mlr-org.com) is an extension package of the machine-learning framework [mlr3](https://mlr3.mlr-org.com).
  It adds support for spatiotemporal resampling methods and their visualization.
  Spatiotemporal resampling methods are needed to assess model performance in a variety of predictive situations in which spatial, temporal, or spatiotemporal autocorrelation is present.
  Cross-validation performance estimates may be biased when this is ignored.
  Currently various R packages implementing different spatiotemporal partitioning strategies exist: sperrorest, blockCV, CAST.
  The goal of [mlr3spatiotempcv](https://mlr3spatiotempcv.mlr-org.com) is to gather the available spatiotemporal resampling methods in R and make them available to users through a simple and common interface.
  This is made possible by integrating the package directly into the [mlr3](https://mlr3.mlr-org.com) machine-learning framework, which already has support for generic non-spatiotemporal resampling methods such as random partitioning.
  This simplifies the step of integrating package-specific syntax into an overarching machine-learning pipeline, making it easier for users to choose from a variety of different spatiotemporal resampling methods.
  The users' decision to use a specfic resampling method should depend on the predictive task at hand, the autocorrelation within the data, and the structure of the sampling design used to collect the data.
keywords:
  formatted: [cross-validation, predictive performance, machine learning, autocorrelation, spatial, temporal, "\\proglang{R}"]
  plain:     [cross-validation, predictive performance, autocorrelation, spatial, temporal, R]
preamble: >
  \usepackage{amsmath}
  \usepackage{amssymb}
  \usepackage{booktabs}
  \usepackage{longtable}
  \usepackage{adjustbox}
  \usepackage{multirow}
  \usepackage{tabularx}
  \usepackage{placeins}
  \usepackage{scrextend}
  \usepackage{tablefootnote}
  \newcommand{\specialcell}[2][l]{%
    \begin{tabular}[#1]{@{}l@{}}#2\end{tabular}}
tables: true
bibliography: paper.bib
output:
  bookdown::pdf_book:
    base_format: rticles::jss_article
    includes:
      in_header: header.tex
---

```{r setup, echo=FALSE, purl=FALSE}
# important for correct figure placement
# see https://stackoverflow.com/a/49395389/4185785
knitr::knit_hooks$set(plot = function(x, options) {
  knitr::hook_plot_tex(x, options)
})
```

```{r setup-2, echo=FALSE, purl=T}
# for knitr spin later
knitr::opts_chunk$set(fig.path = "./paper/figs/",
  cache = TRUE,
  cache.lazy = TRUE)
```

# Introduction {#sec:intro}

Spatial and spatiotemporal prediction tasks are common in applications ranging from environmental sciences to archaeology and epidemiology.
While sophisticated mathematical frameworks have long been developed in spatial statistics to characterize predictive uncertainties under well-defined mathematical assumptions such as intrinsic stationarity [e.g., @cressie1993], computational estimation procedures have only been proposed more recently to assess predictive performances of spatial and spatiotemporal prediction models [@brenning2005; @brenning2012; @pohjankukka2017; @roberts2017].

Although alternatives such as the bootstrap exist and have some advantages [@efron1983; @hand1997], cross-validation is a particularly well-established, easy-to-implement algorithm for *model assessment* of supervised machine-learning models [@efron1983 and next section] and *model selection* [@arlot2010].
In its basic form, it is based on resampling the data without paying attention to any possible dependence structure, which may arise from, e.g., grouped or structured data, or underlying environmental processes inducing some sort of spatial coherence at the landscape scale.
In treating dependent observations as independent, or ignoring autocorrelation, cross-validation test samples may in fact be heavily correlated with, or even pseudo-replicates of, the data used for training the model, which introduces a potentially severe bias in assessing the transferability of flexible machine-learning models.

This cross-validation bias is well-known in spatial as well as non-spatial prediction [@brenning2005; @brenning2008; @arlot2010; @roberts2017] and in forecasting [@bergmeir2018].
It is most easily understood from a predictive modeling perspective by focusing on the question where (and when) the model should be used for prediction.
In crop classification from remotely-sensed data, for instance, learning samples routinely contain multiple grid cells from a sample of fields with known crop type, for instance 2000 grid cells from 100 fields scattered across a large study region.
The purpose of training a model on this particular sample is to make predictions on other, new fields within the same geographic domain [*intra-domain* prediction, @brenning2005] --- not *within* the same field, which obviously presents only a single crop type that is already known from the training sample.
In this specific situation it would therefore seem rather unwise to train a model on a simple random subsample of grid cells, and to test it on the remaining data, using other grid cells from the same fields, as if we wanted to predict within a field.
The results from this performance assessment would be over-optimistic, and perhaps badly so.
To mimic the predictive situation for which the model is trained, one would rather have to resample at the level of fields, not grid cells [@pena2015].
If the model was to be applied to adjacent agricultural regions, i.e., outside the learning sample's spatial domain [*extra-domain* prediction, @brenning2005], it would even seem necessary to resample at a higher level of spatial aggregation, i.e. at the level of agricultural sub-regions within the learning sample, in order to realistically mimic the actual prediction task.
The cross-validation resampling needed therefore depends as much on the prediction task itself as on the data structure or dependency at hand.

While it is not the purpose of this article to recommend specific resampling schemes for specific use cases, this example may suffice to motivate the use of appropriate spatial and spatiotemporal cross-validation techniques, and the need for a unified framework and computational toolbox that accommodate a variety of prediction tasks that may be applicable to a broad range of application scenarios.
\pkg{mlr3spatiotempcv} is such a toolbox.

This toolbox, implemented as an open-source R package, builds upon and generalizes several existing toolboxes that have been developed in recent years for more specific settings (Table&nbsp;\@ref(tab:sptcv-methods)).
The earliest and most comprehensive of these implementations is the \pkg{sperrorest} R package [@brenning2012], which provides an extensible framework and includes predefined resampling strategies based on, for example, blocking, clustering, and buffering.
In contrast, \pkg{blockCV} and \pkg{ENMeval} were developed for block and buffer resampling with a focus on species distribution modeling [@blockCV; @rest2014; @muscarella2014].
Neither of these however have been integrated into established machine-learning frameworks such as \pkg{mlr}/\pkg{mlr3} or \pkg{caret}/\pkg{tidymodels}, and all of them lack support of temporal prediction tasks.
The \pkg{CAST} package, in contrast, focuses on spatiotemporal prediction tasks and makes use of some functions of the \pkg{caret} framework [@cast; @meyer2018].
One limitation of these packages is the sole focus on model assessment, while the proposed implementation within the \pkg{mlr3} framework offers a seamless integration into model selection.
It is worth noting that a spatial cross-validation library named \pkg{spacv} has recently been developed for Python3, which can be used with the \pkg{scikit-learn} machine-learning framework [@pedregosa2011].

Thus, \pkg{mlr3spatiotempcv} implements for the first time a comprehensive state-of-the-art compilation of spatial and spatiotemporal partitioning schemes that is well-integrated into a comprehensive machine-learning framework in R, the \pkg{mlr3} ecosystem [@mlr3].
This package is furthermore equipped with a variety of two- and three-dimensional visualization capabilities.
Our hope is that this implementation will facilitate reproducible geospatial modeling and code-sharing across a broad range of application domains.

The purpose of this paper is to give an overview of the methods implemented in the R package \pkg{mlr3spatiotempcv}.
After presenting the conceptual background in the following section, the overall structure of the \pkg{mlr3spatiotempcv} package is outlined.
Next, various spatial and spatiotemporal partitioning techniques are contrasted and compared, before their application is demonstrated in a machine-learning model assessment in the following section.
Finally, limitations of existing methods are discussed and an outlook is given.

# Spatial and spatiotemporal cross-validation

In cross-validation for predictive model assessment, we consider the following formal setting.
We are interested in predicting a numerical or categorical response $y$ of an object or instance using a feature vector $\mathbf{x} = (x^{(1)}, \ldots, x^{(p)})^t\in\mathbb{R}^p$ and a model $\hat{f}_\mathcal{L}$ that has been trained on a learning sample $\mathcal{L} = \{(y_i, \mathbf{x}_i),\ i = 1, ..., n\}$.
Our goal is to estimate the expected value of the performance of $\hat{f}_\mathcal{L}$,
\[
\mathit{perf(\hat{f}_\mathcal{L})} := E(l(Y,\hat{f}_\mathcal{L}(X))),
\]
where $l$ is a real-valued loss function, and the expected value is with respect to the probability distribution of $X$, the features of an instance $(Y,X)$ drawn randomly from the underlying population.
This is referred to as the *actual* or *conditional* performance measure as it is conditional on $\mathcal{L}$ [@hand1997].
The loss function can take a variety of forms such as the misclassification error $I(Y\neq\hat{f}_\mathcal{L}(X))$ in classification, or the squared error $(Y-\hat{f}_\mathcal{L}(X))^2$ in regression, among many other possible measures.
The choice of the performance measure is equally critical as the choice of the estimation procedure, but it is beyond the scope of this contribution to discuss performance metrics for regression and classification (see, e.g., @hand1997 for classification, and @hyndman2006 for regression and forecasting tasks).

Since we only have a sample $\mathcal{T}$ of test data drawn from the population, we can only *estimate* the conditional performance of $\hat{f}_\mathcal{L}$:
\[
\widehat{\mathit{perf}}_T(\hat{f}_\mathcal{L}) = \frac{1}{|\mathcal{T}|}\sum_{(Y,X)\in\mathcal{T}}l(Y,\hat{f}_\mathcal{L}(X)).
\]
This representation as a point estimator of $\mathit{perf(\hat{f}_\mathcal{L})}$ underlines the importance of using a random sample for model assessment to avoid estimation bias. Other estimators than the simple mean may be required when $\mathcal{T}$ is not a simple random sample, for instance a stratified random sample [e.g., @thompson2012].
As always, judgment sampling may lead to uncontrollable bias.

Since re-using the learning sample $\mathcal{L}$ for testing, i.e. $\mathcal{T}:=\mathcal{L}$, would yield the over-optimistic *resubstitution* or *apparent* performance, cross-validation partitions the sample $\mathcal{L}$ into disjoint training and test sets.
Specifically, $\mathcal{L}$ is split into $k$ partitions,
\[
\mathcal{L} = \mathcal{L}_1 \cup \ldots \cup \mathcal{L}_k,\qquad \mathcal{L}_i\cap \mathcal{L}_j = \emptyset\quad \textrm{for all}\ i\neq j,
\]
and a model $\hat{f}_{(i)}$ is fitted on $\mathcal{L}_{(i)} := \mathcal{L}\setminus \mathcal{L}_i$, while $\mathcal{L}_i$ is withheld for testing.
This is repeated for $i=1,\ldots,k$ in order to effectively use the entire sample for testing, while keeping training and test sets disjoint at all times.
The $k$-fold CV estimator can therefore be written as
\[
\widehat{\mathit{perf}}_{\mathcal{L}, CV}(f) := \frac{1}{k}\sum_{i=1}^k\widehat{\mathit{perf}}_{\mathcal{L}_i}(\hat{f}_{\mathcal{L}_{(i)}}),
\]
where $f$ is a machine-learning algorithm, i.e. a mapping that trains a model $\hat{f}_\mathcal{S}$ using any suitable training sample $\mathcal{S}$.
The use of $k=5$ or $k=10$ folds is most commonly seen in practice, and these preferences are also supported by theory [@bengio2004; @cawley2010].
The $k$-fold CV estimator of model performance is a nearly unbiased estimator of the conditional performance measure when the observations were drawn independently [@efron1983].
Since $\widehat{\mathit{perf}}_{\mathcal{L}, CV}(f)$ still depends on the particular partitioning chosen for $\mathcal{L}$, it is sometimes recommended to repeat the estimation using different random partitionings ($r$-repeated $k$-fold cross-validation) to reduce the influence of randomness when creating partitions [@vanwinckelen2012].

In traditional cross-validation, the partitioning is based on uniform random resampling, which ignores spatial or temporal autocorrelation or any existing grouping structure as well as the structure of the prediction task, and may result in over-optimistic performance estimates.
Several approaches have therefore been proposed in the literature and implemented in software to accommodate a variety of predictive situations (Table&nbsp;\@ref(tab:sptcv-methods)).

Approaches based on *spatial blocking* or *grouping* require either the construction of spatial zones, or the use of pre-existing spatial structures in the data.
Let's refer to these spatial units or zones as $\mathcal{Z}_i$, $1\le i\le n_z$.
These zones are often constructed to serve as the $k=n_z$ spatial partitions, for example by performing $k$-means clustering of the sample coordinates [@russ2010], which we refer to as *coordinate-based clustering*, or generating the desired number of rectangular blocks.
The zones may also be defined by a modeler based on an arbitrary (e.g., polygonal) partitioning of the study region, which we refer to as *custom resampling*.
Similarly, the data can be partitioned in feature space instead of geographic space, which has been referred to as *environmental blocking* [@roberts2017].

When $n_z$ is much larger than the desired number of folds, $k$, then a partitioning can be applied to the zones themselves. In this case, the zone indices $1, \ldots, n_z$ are grouped into $k$ equally sized subsets $\mathcal{I}_1, \ldots, \mathcal{I}_k$.
This approach has been applied, for example, in spatial CV at the agricultural field level [@pena2015].
We would like to emphasize the conceptual distinction between CV *at the group (or block) level*, referring to this scenario, and the various previously types of block CV, where the blocks or groups themselves define the CV partitions.

A variant of cross-validation is leave-one-out (LOO) cross-validation, which has long been established in geostatistics [@cressie1993], sometimes with a focus on the spatial distribution of LOO error [@willmott2006].
Although this is just a special case of non-spatial CV with $k=n$, it is sometimes also referred to as spatial CV [@willmott2006].

Spatial variants have been proposed that apply an exclusion buffer to the test locations to separate them from the training data [@brenning2005].
We refer to this resampling scheme as *spatial buffering*.
One approach that has been proposed for defining a separation distance is to use the range of autocorrelation of model residuals to determine the buffer distance as this ensures independence conditional on the predictors [@brenning2005; @roberts2017].
When data is grouped, e.g., due to multi-level sampling designs or the study of spatial objects, it has been proposed to apply LOO at the site level [@martin2008; @kasurak2011] or, in animal movement studies, at the animal level [@anderson2005].
We will broadly refer to such groups of observations as 'blocks' in a generic sense, and therefore refer to this type of LOO-CV as *leave-one-block-out CV*.

It should be noted that $k$-fold cross-validation with a large value of $k$, and LOO-CV in particular ($k=n$), is not only very time-consuming since the model has to be trained $k$ times; these models will also be nearly identical since only a tiny fraction of the data is withheld, and therefore estimation bias increases.
'Pure' LOO-CV is therefore not recommended for machine-learning model assessment.

In the purely temporal domain, a special case is to leave out temporal observational units (or time slices; leave-time-out or LTO CV), as in leave-one-year-out CV [@anderson2005; @brenning2005].
Cross-validation and hold-out validation strategies for time series have been discussed more extensively in the forecasting literature, considering also the effects of serial autocorrelation [@bergmeir2018].

Turning to prediction tasks with spatiotemporal data, various spatial, temporal, or spatiotemporal partitioning strategies are being used, depending on the specific study objectives.
While the former two ignore the spatial and temporal dimension of the data, respectively, it has also been proposed to leave out random subsets of locations and time points [@meyer2018] or spatiotemporal clusters [@cluto].
<!-- AB: This short paragraph does certaintly not adequately describe Meyer's LLTO with its unique buffer in space and time dimensions. But I'm not sure if it's worth the effort. -->

# mlr3spatiotempcv within the mlr3 ecosystem

With the increased awareness of the importance of spatial and spatiotemporal resampling strategies and the growing popularity of R in environmental modeling and geocomputation, it is important to equip machine-learning frameworks such as \pkg{mlr3} with suitable algorithms.
In this context, the \pkg{mlr3} ecosystem stands out as a unified, object-oriented and extensible framework designed to accommodate numerous machine-learning tasks with a variety of learners, feature and model selection tools, and model assessment capabilities [@mlr3; @mlr3book].
All of these are supported by advanced visualization tools, which are particularly important in a spatial and spatiotemporal setting.

With its integrative approach and its aim to provide long-term support, \pkg{mlr3} overcomes the challenges of combining multiple specialized packages with poorly standardized interfaces.
Issues that practitioners often face include varying argument lists of learners, different return values of `predict` methods, and support for only specific feature types.
These challenges result in substantial overhead and possible reproducibility issues, which are exacerbated by asynchronous development timelines of different components of the machine-learning pipelines.

Within the \pkg{mlr3} ecosystem, partitioning strategies are represented by their own objects of class \texttt{Resampling}, most of which are available within \pkg{mlr3} itself (e.g., random CV); other specialized strategies (e.g., \texttt{TaskClassifST} or \texttt{TaskRegrST}) are defined in extension packages such as \pkg{mlr3spatiotempcv}.
In the machine-learning pipeline, these objects define the data splits used for model assessment and selection (hyperparameter tuning) by machine-learning algorithms.
Spatial and spatiotemporal partitioning techniques in \pkg{mlr3spatiotempcv} are currently mostly imported and interfaced from other packages, in particular \pkg{sperrorest}, \pkg{blockCV} and \pkg{CAST} [@brenning2012; @blockCV; @cast], in order to expose them to \pkg{mlr3} functionality.
To reduce dependencies, some methods were re-implemented instead of importing them from upstream packages.

Resampling objects in \pkg{mlr3spatiotmpcv} inherit from class \texttt{mlr3::Resampling} and can be created from established object classes for geospatial data in R, including simple features [@pebesma2018], which facilitates their integration into domain-specific workflows in the geospatial sciences.
Support for projected (planar) and unprojected (geographic) coordinate reference systems (CRS) currently varies depending on the partitioning techniques used, since these inherit their behavior from the underlying upstream R package.

Partitioning objects in \pkg{mlr3spatiotempcv} are equipped with generic `plot()` and `autoplot()` methods that visualize the groups created.
`autoplot()` is \pkg{ggplot2}-based and uses [ggplot2](https://ggplot2.tidyverse.org) [@ggplot2] in two-dimensional geographic space and [plotly](https://github.com/ropensci/plotly) [@plotly] in three dimensions, i.e., geographic space plus time.

While \pkg{mlr3spatiotempcv} solely focuses on spatiotemporal resampling methods and their visualization, other packages such as \pkg{mlr3spatial} or \pkg{mlr3temporal} are planned in the mlr3 ecosystem to provide dedicated spatiotemporal learner and prediction methods.

# Spatiotemporal partitioning methods

\pkg{mlr3spatiotempcv} currently implements the partitioning methods identified in Table&nbsp;\@ref(tab:sptcv-methods) with their \pkg{mlr3} class name.
Several of the implemented algorithms are themselves versatile toolboxes with multiple options.
Comprehensive and up-to-date information can be found in the package's online documentation (<https://mlr3spatiotempcv.mlr-org.com>).
The following sections give an overview of most existing partitioning strategies and their visualization options.
The available methods are further discussed in section \@ref(sec:disc).

\begin{table}[h]
  \centering
  \footnotesize
  \caption[t]{Spatiotemporal resampling methods available in the mlr3 ecosystem.
    Column name shows the mlr3 method name as found in the `mlr3::mlr\_resamplings` dictionary.
    Column "Count" refers to the number of studies which were found to have used this resampling technique until May 2021.
    Literature appearances were only collected for methods with a "spcv" or "sptcv" prefix as methods which rely on custom grouping ("custom\_cv" and "cv") do not have a dedicated name or identifier to make them detectable in research papers.
    For each method, up to three randomly chosen references were added to the table as footnotes.}
  \begingroup
    \begin{tabular}{lllll}
      \\
      Type                            & Name                        & R Package     & Sub-Type  & Count\\
      \toprule
      \multirow{2}{*}{Spatial Leave-one-out}        &  \texttt{"spcv\_buffer"} \tablefootnote{\label{ploton2020}\cite{ploton2020}} \tablefootnote{\label{diesing2020}\cite{diesing2020}} & \pkg{blockCV}  & buffer, LOO & 2   \\
      \cmidrule{2-5}
       & \texttt{"spcv\_disc"} \tablefootnote{\label{endicott2017}\cite{endicott2017}} \tablefootnote{\label{karasiak2021}\cite{karasiak2021}} \tablefootnote{\label{moller2021}\cite{moller2021}} & \pkg{sperrorest}      & buffer, multiple observations  & 3   \\
      \midrule
      \multirow{4}{*}{Leave-one-block-out CV} & \texttt{"spcv\_coords"}  \tablefootnote{\label{morera2021}\cite{morera2021}} \tablefootnote{\label{geiss2017}\cite{geiss2017}} \tablefootnote{\label{wu2020}\cite{wu2020}} & \pkg{sperrorest}       &  clustering & 6 \\
            \cmidrule{2-5}
                                      & \texttt{"spcv\_tiles"} \tablefootnote{\label{bebber2017}\cite{bebber2017}} \tablefootnote{\label{brenning2015}\cite{brenning2015}} \tablefootnote{\label{zurell2020}\cite{zurell2020}} & \pkg{sperrorest}    &  geometric &  4  \\
                                                  \cmidrule{2-5}
                                      &  \texttt{"custom\_cv"}           & \pkg{mlr3} & custom  & - \\
      \midrule
      \multirow{4}{*}{CV at the block level} & \texttt{"spcv\_block"}  \tablefootnote{\label{jensen2021}\cite{jensen2021}} \tablefootnote{\label{escobar2021}\cite{escobar2021}} \tablefootnote{\label{stewart2021}\cite{stewart2021}} & \pkg{blockCV}       &  geometric & 28 \\
  \cmidrule{2-5}
                                      & \texttt{"cv"}  & \pkg{mlr3}    &  custom, honors grouping &  -  \\
  \cmidrule{2-5}
                                      & \texttt{"spcv\_env"} \footref{morera2021}  & \pkg{blockCV}    &  clustering, feature space &  1  \\
      \midrule
      \multirow{3}{*}{CV for spatiotemporal data} & \texttt{"sptcv\_cstf"}  \tablefootnote{\label{egli2020}\cite{egli2020}} \tablefootnote{\label{gao2019}\cite{gao2019}} \tablefootnote{\label{reitz2021}\cite{reitz2021}} & \pkg{CAST}       &  custom & 6 \\
                                                  \cmidrule{2-5}
                                      & \texttt{"sptcv\_cluto"}  & \pkg{skmeans}    &  clustering & - \\
                                      \bottomrule
    \end{tabular}
  \endgroup\label{tab:sptcv-methods}
\end{table}


On the most upper level, resampling methods are categorized through the way the fold partitioning is done:

- Leaving out single pixels (Spatial Leave-one-out) per fold with an optional buffer
- Leaving out single blocks (Leave-one-block-out CV) per fold with an optional buffer
- Leaving out multiple blocks (CV at the block level) per fold

A finer distinction can then be made by looking at how these groups are formed by the respective individual method:

- Using a geometric-based approach (rectangular or circular)
- Using an unsupervised clustering approach
- Using a custom/external input, i.e. specifying the groups via an external grouping variable

The terminology "block" used in this categorization and in the manuscript in general refers to any kind of regular and irregularly shaped grouping of observations and not necessarily only to a rectangular partitioning as used in some methods.

<!-- explain and introduce buffering -->
The use of a buffer is not a direct grouping characteristic of a partitioning method in our view but only an optional add-on which could potentially be used by any method.
"Buffering" refers to the idea of removing observations located between test and training sets by drawing a circular buffer around one or more observations [@brenning2012; @rest2014; @blockCV].
Within this buffer zone, all observations are removed from the training set, thereby reducing the similarity between training and test set.
Buffering is mostly applied in the coordinate space.
However, there is no practical limitation that would prevent this method to be applied in a 2D + time setting.
Since \pkg{mlr3spatiotempcv} supports two spatial-only "buffering" implementations, (1) `"spcv\_buffer"` from package \pkg{blockCV} and (2) `"spcv\_disc"` from \pkg{sperrorest}, buffering was attributed to the category of spatial partitioning methods (Table&nbsp;\@ref(tab:sptcv-methods)).

<!-- FIXME: graphic here -->

## Spatial Leave-one-out

Spatial Leave-one-out methods start from a single observation in space and create radial (buffer) zones around which define the partitions.

### Spatial Leave-one-out with buffer --- `"spcv_buffer"`

The "buffering" method from the \pkg{blockCV} package is conceptually related to spatial leave-one-out cross-validation.
It comes with optional support for presence/absence data handling, as often used in the field of species distribution modeling [@hijmans2013].
However, by default, the method considers all points for sampling the training and test sets.

In an ecological/species distribution modeling context, the default assumption of a binary response variable is to have *presence/absence* data.
This means all presence and absence values in the response variable are confirmed in their respective status.
The \pkg{blockCV} package implementation also comes with support for *presence/background* data for binary responses.

All other response observations are assumed to be absent without a proof for this assumption.
When setting argument `spDataType = "PB"`, the method only considers the *presence* observations in a CV scenario.
Background data is used for training the model by default unless argument `addBG = FALSE` is set for which only *presence* values not falling within the buffer zone of the respective fold are used for model training.

Due to its similarity to a LOO CV, this method will result in as many train/test evaluations as observations are present.
In the visualization of the first fold in Figure&nbsp;\@ref(fig:buffer) a buffer zone of 1000 m was used without any custom presence/absence treatment of the data.

```{r buffer, fig.cap='Visualization of the spatial buffering method from package blockCV (method "spcv\\_buffer" in  mlr3spatiotempcv). The buffer distance is 1000 m.', out.width="40%", fig.pos="ht"}
resampling_buffer = rsmp("spcv_buffer", theRange = 1000)
resampling_buffer$instantiate(task)

autoplot(resampling_buffer,
  size = 0.8, task = task, fold_id = 1) *
  ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
  ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
```

### Leave-one-disc-out with optional buffer --- `"spcv_disc"`

Leave-one-disc-out resampling from package \pkg{sperrorest} randomly selects a circular test set starting from a single observations and optionally excludes a buffer zone from the remaining training data.
It thus ensures that a minimum separation distance between training and test data is maintained.
Discs are centered at sample locations, their number being specified by the `folds` argument.
It is therefore possible to sample up to $n$ discs without replacement (default) or any number when sampling with replacement (`replace = TRUE`).
The number of discs is specified via the `folds` argument.

This resampling method is, strictly speaking, not a partitioning method since the discs are not resulting in disjoint partitions - partitions will potentially overlap in subsequent folds.
Nevertheless, it is a logical extension of spatial LOO CV.
Depending on the size of the discs, potentially a large number of discs (`folds` argument) is needed to effectively use the entire dataset.

Even though the buffer creates a circular area which defines the test partition, it is not categorized as a "geometric" method as the origin of the circle is observation-based.
In contrast, "geometric" methods do not take into account single observation locations but only focus on the study area extend and will include all observations which fall into their respective covered area.

Leave-one-disc-out resampling becomes spatial LOO CV for a radius of 0 m and when each observation is at a unique location.

<!-- AB: TODO: folds = 5 makes very little sense in the case of LODO-CV, since this would only sample 5 discs, which cover only a small fraction of the study area. Let's use folds = 100, this will at least make readers think about their choice of #folds. -->
```{r disc, fig.cap='Visualization of one training set / test set combination generated with the leave-one-disc-out method from package sperrorest (method "spcv\\_disc" in mlr3spatiotempcv). The disc has a radius of 300 m and is surrounded by a 400-m buffer.', out.width="40%"}
library("mlr3")
library("mlr3spatiotempcv")
task = tsk("ecuador")
resampling_disc = rsmp("spcv_disc", folds = 100, radius = 300L, buffer = 400L)
resampling_disc$instantiate(task)

autoplot(resampling_disc,
  size = 0.8, task = task, fold_id = 1) *
  ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
  ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
```

## Leave-one-block-out Cross-Validation

Leave-one-block-out CV methods partition the dataset in a way that each of the resulting partitions will be used as a fold in the CV.

### Clustering-based: Using coordinate-based clustering - `"spcv_coords"`

Cluster analysis provides a flexible approach to creating irregularly shaped spatial blocks for spatial resampling.
Numerous techniques are available that can potentially be applied to the spatial coordinates of observations, to the features, or to a combination of both.
In spatial model assessment, the focus has been on coordinate-based clustering, and specifically on leave-one-block-out resampling with blocks created by $k$-means clustering of the coordinates [@russ2010].

Coordinate-based clustering for spatial CV [@russ2010; @brenning2012] as implemented in package \pkg{sperrorest} uses the coordinates of all observations to create clusters in the spatial domain with the help of the $k$-means clustering algorithm.
This can be regarded as a leave-one-block-out resampling method, or as a $k$-fold CV in which each test set is a spatial cluster.
This method is referred to as `"spcv_coords"` in \pkg{mlr3spatiotempcv}.

Coordinate-based clustering approach is very versatile as it adapts to irregularly-shaped study areas and ensures that exactly $k$ partitions are created, which are usually or very similar size when the sample locations are spread out evenly.
Nevertheless, despite the random selection of initial cluster centers, repeated partitionings may in some cases be nearly identical.
Also, $k$-means clustering may be less suitable for data sets with pre-existing clusters of points and/or with distant isolated sample locations.
When distinct clusters of points are present, as in multi-level sampling, it may be better to define clusters using a factor variable (see method `"custom_cv"` in section \@ref(sec:custom-cv)).

```{r coords, fig.cap='Leave-one-block-out CV based on $k$-means clustering of the coordinates as implemented in package sperrorest (method "spcv\\_coords" in mlr3spatiotempcv).', out.width="40%", fig.pos="ht"}
resampling_coords = rsmp("spcv_coords", folds = 5)$instantiate(task)

autoplot(resampling_coords,
  size = 0.8, fold_id = 1, task = task) *
  ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
  ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
```

### Geometric: using rectangular blocks --- `"spcv_tiles"`

Leave-one-tile-out resampling is implemented in the `"spcv_tiles"` method imported from package \pkg{sperrorest}.
It uses rectangular blocks that can be rotated (argument `rotation`), and a minimum number or fraction of observations per block can optionally be achieved by iteratively merging small blocks into adjacent blocks  (argument `reassign` in conjunction with `min_n` or `min_frac`).
Block size or number is specified via the argument `dsplit` or `nsplit`, respectively, and square blocks can be obtained with a single (or two identical) `dsplit` value.

Note that the actual number of folds obtained may be smaller than `nsplit[1]*nsplit[2]` (or smaller than what would be expected based on `dsplit`) since some blocks may be empty or (optionally) merged into adjacent folds.
In the example, there are only eleven folds instead of twelve because the southwestern part of the study area's bounding box does not contain observations  (Figure&nbsp;\@ref(fig:tile)).

```{r tile, fig.cap='Leave-one-block-out resampling from package sperrorest (method "spcv\\_tiles" in package mlr3spatiotempcv with argument nsplit = c(3,4) indicating the number of rows and columns).', out.width="40%", fig.pos="ht"}
resampling_tiles = rsmp("spcv_tiles", nsplit = c(3L, 4L))

autoplot(resampling_tiles,
  size = 0.8, fold_id = 1, task = task) *
  ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
  ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
```

### Custom: `"custom_cv"` in mlr3

Support for user-defined partitioning strategies is built into \pkg{mlr3} directly.
In this so-called "Custom CV", users are able to supply an external factor vector with the same length as number of observations.
This partitioning concept should not be mistaken with "group-level resampling" (section \@ref(sec:group-level)), which conducts additional combination of data splits and performs CV at the block level.
Each level of the factor vector will result in one partition.
Alternatively to supplying an external factor vector, the name of a feature (type `character`) present within the task can be supplied via argument `col`.

The following example was taken from `sperrorest::partition_factor()` because the resulting partitions separate nicely from each other in a visual way.

<!-- TODO: AB: This diagram is inconsistent with the other diagrams - should display training and test samples. -->
```{r custom-cv, fig.cap='Leave-one-level-out (custom) resampling from package mlr3 (method "custom\\_cv"). A factor variable is used to define the partitions. Each color represents one partition.', out.width="40%", fig.pos="ht"}
breaks = quantile(task$data()$dem, seq(0, 1, length = 6))
zclass = cut(task$data()$dem, breaks, include.lowest = TRUE)

resampling_custom = rsmp("custom_cv")
resampling_custom$instantiate(task, f = zclass)

autoplot(resampling_custom, size = 0.8, task = task) *
  ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
  ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
```

## Cross-Validation at the block level

Methods which operate on the block level create dataset splits which are then combined to form the final partitions for the CV folds.
In the special case of an equal amount of dataset splits and requested CV folds, these methods would perform a Leave-one-block-out CV.

### Geometric: using rectangular blocks --- `"spcv_block"`

The `"spcv_block"` method from package \pkg{blockCV} supports both random and systematic resampling of square blocks (`rsmp("spcv_block")` with argument `selection = "random"` and `"systematic"`, respectively; Figure&nbpsp;~\@ref(fig:block-random) and \@ref(fig:block-systematic)).
This implementation comes with specific options that are designed for modeling presence-only data, which is a typical situation in species distribution modeling.
Users can also supply a user-defined polygon via argument `rasterLayer` with predefined blocking zones.

Block sizes (in meters) are determined by the `range` argument.
Alternatively, rectangular blocks can be created by specifying the number of desired rows and columns (arguments `rows` and `cols`).

```{r block-random, fig.cap='Random resampling of square spatial blocks using the implementation in package blockCV (method "spcv\\_block" with option selection = "random" in mlr3spatiotempcv). The size of the squares is 1000 m, and four out of the 19 blocks were assigned to this test sample.', out.width="40%", fig.pos="ht"}
resampling_block_random = rsmp("spcv_block", range = 1000, folds = 5)

autoplot(resampling_block_random,
  size = 0.8, fold_id = 1, task = task,
  show_blocks = TRUE, show_labels = TRUE) *
  ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
  ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
```

In systematic resampling, the blocks are numbered row by row, and blocks $i+j\cdot\texttt{folds}$ are assigned to fold $i$.
This may create undesired patterns when the number of columns is equal to or a multiple of the number of folds.

```{r block-systematic, fig.cap='Sytematic resampling of square spatial blocks using the implementation in package blockCV (method "spcv\\_block" with option selection = "systematic" in mlr3spatiotempcv). The size of the squares is 1000 m, and four out of the 19 blocks were assigned to this test sample.', out.width="40%", fig.pos="ht"}
resampling_block_systematic = rsmp("spcv_block",
  range = 1000, folds = 5,
  selection = "systematic"
)

autoplot(resampling_block_systematic,
  size = 0.8, fold_id = 1, task = task,
  show_blocks = TRUE, show_labels = TRUE) *
  ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
  ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
```

<!--

##### Option: selection = "checkerboard"

-->

The *checkerboard* partitioning is a special case of a systematic block partitioning (`selection = "checkerboard"`).
It inherently supports only two folds, making it less appealing than the more commonly used five- or ten-fold resampling, which achieve larger training set sizes.
 

<!--
AB:
The text previously stated that the range argument is ignored. This can't be true, there must be some argument that controls the size of checkerboard fields.
-->


<!--
AB: Checkerboard pattern is just a special case of a systematic pattern and likely not of great practical relevance because there are only two folds -> omit figure.

```{r block-checkerboard, fig.cap='Checkerboard resampling of square spatial blocks using the implementation in package blockCV (method "spcv\\_block" with option selection = "checkerboard" in mlr3spatiotempcv). The size of the squares is 1000 m, and eleven out of the 19 blocks were assigned to this test sample.', out.width="40%", fig.pos="ht!"}
resampling_block_checkerboard = rsmp("spcv_block",
  range = 1000, folds = 2,
  selection = "checkerboard")

autoplot(resampling_block_checkerboard,
  size = 0.8, fold_id = 1, task = task,
  show_blocks = TRUE, show_labels = TRUE) *
  ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
  ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
```

-->




<!--
AB: This figure and subsubsubsection takes up a lot of space for very little additional information.


```{r block-rows-and-cols, fig.cap='Random resampling of a specifid number of rectangular blocks as implemented in package blockCV (method "spcv\\_block" in mlr3spatiotempcv with arguments rows = 6 and cols = 3).', out.width="40%", fig.pos="ht"}
resampling_block_rows_cols = rsmp("spcv_block",
  rows = 6, cols = 3, folds = 5
)

autoplot(resampling_block_rows_cols,
  size = 0.8, fold_id = 1, task = task,
  show_blocks = TRUE, show_labels = TRUE) *
  ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
  ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
```

\newpage

-->

### Custom: `"cv"` in mlr3 {#sec:group-level}

Group-level CV is based on the idea that an inherent grouping structure is present the observations or the sampling design in space and/or in time, which can be used to determine partitions.
In contrast to blocking or clustering, the spatial or temporal location is not used explicitly, but additional metadata is exploited such as the membership in a specific agricultural management unit [@brenning2006], or in a site in hierarchical sampling [@kasurak2011].
<!--
This has also been referred to as "target-oriented validation" [@cast].
FIXME:
AB: I don't think I agree with this. My interpretation of the Meyer paper was that in the Meyer paper, locations or time points are the targets. Fields consist of many grid cells, at multiple location.
-->
Even though flexibility with respect to fold creation is limited due to the inherited grouping structure within the data, some implementations allow to specify the resulting number of folds by omitting parts of the dataset.

\pkg{mlr3spatiotempcv} supports two "grouping" implementations: (1) The "leave-location-and-time-out" family from package \pkg{CAST} and (2) "custom resampling" from the \pkg{mlr3} package.

### Clustering: using feature-based clustering --- `"spcv_env"`

The last method from the \pkg{blockCV} package, "environmental blocking", makes use of *k-means* clustering [@hartigan1979a] in a possibly multivariate space.
The user can select a variable via argument `feature` which denotes the variable that will be used to create clusters.
Hereby, $k$-means will use Euclidean distance for cluster creation.
Hence, the selected input variables should be of type numeric.
To avoid a potential bias introduced by features with high variance when selecting multiple features, all features are standardized by default.

The following example clusters by feature "distance to forest".

```{r env-1, fig.cap='Environmental leave-one-block-out CV from package blockCV using a single predictor to define blocks in feature space (method "spcv\\_env" in mlr3spatiotempcv with argument features = "distdeforest").', out.width="40%", fig.pos="ht"}
resampling_env = rsmp("spcv_env",
  features = "distdeforest", folds = 5)

autoplot(resampling_env,
  size = 0.8, fold_id = 1, task = task) *
  ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
  ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
```

It is also possible to cluster based on multiple features:

<!-- TODO: AB: should be combined with the previous figure into a two-panel figure. Differences are much easier to recognize if plotted next to each other. -->
```{r env-2, fig.cap='Environmental leave-one-block-out CV from package blockCV using two predictors to define blocks in feature space (method "spcv\\_env" in mlr3spatiotempcv with argument features = c("distdeforest", "slope")).', out.width="40%", fig.pos="ht"}
resampling_env_multi = rsmp("spcv_env",
  features = c("distdeforest", "slope"), folds = 5)

autoplot(resampling_env_multi,
  size = 0.8, fold_id = 1, task = task) *
  ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
  ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
```
<!-- AB: TODO: In general, the code would look much simpler if we could get rid of the scale_x/y_continuous() calls. Improve default settings of autoplot()? -->


## Cross-Validation for spatiotemporal data

Some methods have the ability to operate in multiple spaces, i.e. spatial, temporal or spatiotemporal (2D + time).
To avoid redundancy and putting too much weight on certain methods, only the spatiotemporal examples of these methods will be shown in the following sections.
For the respective other spaces, usually only either the space or time coordinates need to be omitted from the user input.

### Custom: "Leave-location-and-time-out" --- `"spcv_cstf"`

Leave-location-and-time-out (LLTO) from package \pkg{CAST} is an implementation of spatiotemporal resampling method [@meyer2018].
It requires both a spatial and a temporal variable which are used to separate observations in a multi-dimensional space.
It comes with satellite methods named "leave-time-out" (LTO) and "leave-location-out" (LLO) which only operate in a two-dimensional space.

In this example the `cookfarm` dataset is used because it contains the variable ("Date") which serves as the temporal component in the dataset.

The sub-methods "Leave-Time-Out" (LTO) and "Leave-Location-Out" (LLO) are conceptually similar to the "cv" method with a custom grouping from \pkg{mlr3} as they perform a CV at the block level using a predefined grouping structure.

Two visualization types are supported by `mlr3spatiotempcv::autoplot()` for this method: a two-dimensional and a three-dimensional one which can be selected via the logical argument `plot3D`.
The 3D visualization (i.e. 2D + time) is done via package \pkg{plotly}.
Because a dynamic image cannot be included in this manuscript, a static version, which can be generated by setting `static_image = TRUE`, is shown.

In \pkg{mlr3spatiotempcv} the method is named `"sptcv_cstf"` which is an acronym originating from the underlying upstream implementation in package \pkg{CAST} `CreateSpacetimeFolds()`.

#### Leave-Time-Out (LTO)

To better showcase the partitioning of the "Leave-Time-Out" (LTO) method, the temporal variable `Date` was adjusted in this example.

The following code uses the `cookfarm` dataset as the base, modifies the `Date` variable in such a way that it contains five unique levels and then creates a spatiotemporal regression task in \pkg{mlr3spatiotempcv} (Figure&nbsp;\@ref(fig:lto)).

```{r, results='hide'}
data = cookfarm_sample
data$Date = rep(c(
  "2020-01-01", "2020-02-01", "2020-03-01", "2020-04-01",
  "2020-05-01"), times = 1, each = 100)
b = mlr3::as_data_backend(data)
task_spt = TaskRegrST$new(
  id = "cookfarm", b, target = "PHIHOX",
  extra_args = list(
    coordinate_names = c("x", "y"), coords_as_features = FALSE,
    crs = 26911)
)

resampling_cstf_time = rsmp("sptcv_cstf", folds = 5, time_var = "Date")
resampling_cstf_time$instantiate(task_spt)

autoplot(resampling_cstf_time,
  fold_id = 5, task = task_spt, plot3D = TRUE
)
```

```{r lto, echo=FALSE, out.width="70%", fig.cap='Perspective plot of leave-time-out CV from package CAST (method "sptcv\\_cstf" and argument time\\_var = "Date"). Only five folds and five time points were used in this example. Note that the blue dots correspond to five discrete time levels, which appear as a point cloud due to the viewing angle.', fig.pos="ht"}
knitr::include_graphics("lto.png")
```

#### Leave-Location-Out (LLO)

Method "Leave-Location-Out" (LLO) works similar to "Leave-Time-Out" (LTO) in that it operates in a two-dimensional space.
Here, specific locations are left out individually for forming test partitions while the temporal information is ignored (Figure&nbsp;\@ref(fig:llo)).

```{r results='hide'}
resampling_cstf_loc = rsmp("sptcv_cstf", folds = 5, space_var = "SOURCEID")
resampling_cstf_loc$instantiate(task_spt)

autoplot(resampling_cstf_loc,
  fold_id = 5, task = task_spt, plot3D = TRUE)
```

```{r llo, echo=FALSE, out.width="70%", fig.cap='Perspective plot of leave-location-out CV from package CAST (method "sptcv\\_cstf" and argument space\\_var = "SOURCEID"). The data is viewed from the future towards the past.', fig.pos="ht"}
knitr::include_graphics("llo.png")
```

#### Leave-Location-and-Time-Out (LLTO)

The "Leave-Location-and-Time-Out" (LLTO) method combines both "Leave-Time-Out" (LTO) and "Leave-Location-Out" (LLO).
It creates partitions that operate on spatiotemporal clusters to reduce both spatial and temporal autocorrelation.
If there are multiple observations over time per location, and the modeling purpose is to reduce the bias in the predictions as potentially introduced by spatial as well as temporal autocorrelation, LLTO might be an appropriate choice.
To reduce autocorrelation in both dimensions, the methods omits observations as the splitting in test and train sets only provides separation in one dimension whereas two (space and time) are needed to account for both types, spatial and temporal autocorrelation.
In other words, accounting for one dimension as in Figure&nbsp;\@ref(fig:lto) or Figure&nbsp;\@ref(fig:llo), by only having one time step or location in either test or training set, would have no effect on the respective other.
Thus, the removal of observation can be seen as a proxied buffering in multiple dimensions as shown in Figure&nbsp;\@ref(fig:llto).

```{r results='hide'}
resampling_cstf_time_loc = rsmp("sptcv_cstf",
  folds = 5,
  space_var = "SOURCEID", time_var = "Date")
resampling_cstf_time_loc$instantiate(task_spt)

autoplot(resampling_cstf_time_loc,
  fold_id = 4, task = task_spt, plot3D = TRUE,
  show_omitted = TRUE)
```

```{r llto, echo=FALSE, out.width="70%", fig.cap='Perspective plot of leave-location-and-time-out CV from package CAST (method "sptcv\\_cstf" and arguments time\\_var = "Date" and space\\_var = "SOURCEID"). The grey points are excluded from both the training and the test set in this fold.', fig.pos="ht"}
knitr::include_graphics("llto.png")
```

### Clustering: using CLUTO --- `"sptcv_cluto"`

Considering the wealth and continuing development of spatial and spatiotemporal partitioning techniques for specific applications, we will refrain from providing a complete account of these algorithms.
At present, \pkg{mlr3spatiotempcv} also supports spatiotemporal partitioning using the versatile CLUTO clustering algorithm [@cluto].
CLUTO is available in R through the \pkg{skmeans} package, which provides an interface to a downloadable compiled library with a restriction to non-commercial uses (see `help("ResamplingSptCVCluto", package = "mlr3spatiotempcv")` for more information).
With respect to functionality, \pkg{mlr3spatiotempcv} supports two-dimensional clustering based on coordinates, time or features and three-dimensional clustering on coordinates and time.


<!-- Spatial blocking divides the study area into different zones [russ2010; @bahn2012; @wenger2012; @blockCV]. -->
<!-- Several methods have been implemented to create rectangular as well as irregularly shaped blocks.  -->
<!-- These blocks can be used for leave-one-block-out resampling, or they can themselves be grouped into $k$ partitions for a $k$-fold CV at the block level. -->

<!-- \pkg{mlr3spatiotempcv} supports multiple resampling methods that are based on blocks:  -->
<!-- (1) "Spatial blocking" from package \pkg{blockCV} implements $k$-fold CV resampling at the level of square or rectangular blocks, while (2) "Spatial tiles" from \pkg{sperrorest} offers leave-one-block-out resampling with square or rectangular, possibly rotated blocks. -->
<!-- In addition, irregularly shaped blocks are available (3) through coordinate-based clustering as a leave-one-block-out technique from \pkg{sperrorest} (method `"spcv_coords"`, Section&nbsp;\@ref(sec:cluster-cv)), and (4) as a CV at the block level where blocks are defined by a factor variable that defines zones or groups (method `"custom_cv"` in \pkg{mlr3}, Section&nbsp;\@ref(sec:custom-cv)). -->



### Clustering-based resampling {#sec:cluster-cv}



# Step-by-step example: Comparing spatial and non-spatial CV {#sec:case-study}

We use a well-known case study to demonstrate the application of spatial and non-spatial resampling techniques for model assessment in \pkg{mlr3spatiotempcv}.
The objective of landslide susceptibility modeling is to predict how prone to landslide initiation a location is.
Models are fitted to historical landslide occurrences, but they need to learn generalizable relationships between predisposing variables and the response as opposed to perfectly reproducing or memorizing the historical distribution.
This binary classification task on landslides in Ecuador [@muenchow2012] is available as a built-in task via `tsk("ecuador")`, but we generate it from the learning sample.
Random forest is used as a classifier, and the area under the ROC curve (AUROC) as the performance measure.

Spatial CV is implemented in the form of leave-one-block-out CV using coordinate-based $k$-means clustering to generate  irregularly shaped blocks of roughly equal size.
This approach is better suited for the shape of the present study area than a rectangular partitioning.
Figures&nbsp;\@ref(fig:vis-spcv)) and&nbsp;\@ref(fig:vis-nspcv)) show the contrasting distributions of training and test samples.
For demonstration purposes we use only four CV folds and two repetitions.


## Task preparation

In \pkg{mlr3}, machine-learning tasks with their respective dataset and response variable are represented by objects of the class `Task`. \pkg{mlr3spatiotempcv}'s spatial and spatiotemporal machine-learning tasks are derived from this superclass.
Specifically, the `TaskClassifST` and `TaskRegrST` classes for classification and regression tasks require several additional arguments that must be passed as a named list using the `extra_args` argument:

- `coordinate_names`: Names of the features that represent the spatial coordinates.
  This is automatically inferred when a `sf` object is passed.
- `coords_as_features`: Whether the coordinates should be used as features; by default they are not.
- `crs`: The coordinate reference system of the data as a PROJ string or EPSG code in the format `ESPG:<code>`.

At first all necessary R packages are loaded and a lower verbosity is set to keep the output tidy.
A random-number seed is set for reproducibility.

```{r load-pkgs}
library("mlr3")
library("mlr3spatiotempcv")

# be less verbose
lgr::get_logger("bbotk")$set_threshold("warn")
lgr::get_logger("mlr3")$set_threshold("warn")

set.seed(42)
```

The task `"ecuador"` is available in \pkg{mlr3spatiotempcv} through `tsk("ecuador")`.
To set it up manually, we proceed as follows:

<!-- AB: TODO: The comment says that b$hash is optional, but the reader will not know what it is good for. A more verbose comment would be helpful, maybe 'optional task identifier' or whatever the hash name may be good for. -->
```{r create-task}
b = mlr3::as_data_backend(ecuador)
b$hash = "_mlr3_tasks_ecuador_" # optional
task = TaskClassifST$new(
  id = "ecuador", b, target = "slides", positive = "TRUE",
  extra_args = list(
    coordinate_names = c("x", "y"), coords_as_features = FALSE,
    crs = "EPSG:32717")
)
```



## Model preparation

Next, the random forest learner (`"classif.ranger"`) is initialized with default hyperparameters and the prediction type is set to `"probability"` because the model is used for soft classification.
A set of commonly used learners is available in package \pkg{mlr3learners} [@mlr3learners], including the random forest implementation of @ranger.

```{r prepare}
library("mlr3learners")

learner = lrn("classif.ranger", predict_type = "prob")
```

## Non-spatial cross-validation

A resampling is generated in \pkg{mlr3} with the `rsmp()` function, which is used to generate a resampling object for four-fold non-spatial CV with two repetitions.
The object is constructed and instantiated with its `$instantiate()` method.

Next, the created resampling object `resampling_nsp` is passed to function `resample()` together with the task and learner objects created earlier to execute the model assessment.
This is the actual, potentially time-consuming CV estimation. With the present settings, eight random forest classifiers are fitted and evaluated in this step.

Model performances are calculated from the CV predictions using the AUROC (`"classif.auc"` in \pkg{mlr3} notation).

```{r rr-nspcv, cache.lazy = FALSE}
resampling_nsp = rsmp("repeated_cv", folds = 4, repeats = 2)
resampling_nsp$instantiate(task)
rr_nsp = resample(
  task = task, learner = learner,
  resampling = resampling_nsp
)

rr_nsp$aggregate(measures = msr("classif.auc"))
```

## Spatial cross-validation via coordinate-based clustering

The model assessment is now repeated using spatial CV resampling, for which we only need to replace `"repeated_cv"` with `"repeated_spcv_coords"`.

```{r rr-spcv, cache.lazy = FALSE}
resampling_sp = rsmp("repeated_spcv_coords", folds = 4, repeats = 2)
resampling_sp$instantiate(task)
rr_sp = resample(
  task = task, learner = learner,
  resampling = resampling_sp
)

rr_sp$aggregate(measures = msr("classif.auc"))
```

## Visualization of CV partitions

Finally, we visualize the partitions that were used during performance estimation making use of the generic `autoplot()` function in package \pkg{mlr3spatiotempcv} (Figure&nbsp;\@ref(fig:vis-spcv)).


```{r vis-spcv, fig.cap="Spatial leave-one-block-out partitioning using coordinate-based clustering to create roughly equally sized polygonal blocks. Due to space limitations only the first two folds of the first repetition are shown.", fig.pos="ht", fig.height=6, fig.width=8}
autoplot(resampling_sp, task, fold_id = c(1:2), size = 0.8) *
  ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
  ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
```

```{r vis-nspcv, fig.cap="Random (non-spatial) four-fold CV partitioning. Only the first two folds of the first repetition are shown.", fig.pos="ht", fig.height=6, fig.width=8}
autoplot(resampling_nsp, task, fold_id = c(1:2), size = 0.8) *
  ggplot2::scale_y_continuous(breaks = seq(-3.97, -4, -0.01)) *
  ggplot2::scale_x_continuous(breaks = seq(-79.06, -79.08, -0.01))
```

## Summary

The non-spatial CV estimate of AUC (0.76) is around 0.13 better compared to the spatial CV estimate of 0.64.
The better performance results from over-optimism in the estimation with non-spatial CV.
Spatial CV, in contrast, provides a better measure of a model's ability to generalize from the training sample --- in this case study, from the specific hillslopes and historical landslides in the training sample.
It is also expected that spatial CV results better reflect the performance of a model on new, spatially separate data.
The magnitude of the difference between spatial and non-spatial CV estimates may depend on the dataset, the strength on spatial or spatiotemporal autocorrelation, and the learner itself.
Algorithms with a higher tendency to overfit to the training set will tend to have a larger spread in such scenarios.

<!-- AB: TODO: Check if the following paragraphs overlaps with the Discussion section; perhaps merge into Discussion. -->
Since spatial CV can also be used for hyperparameter tuning in the \pkg{mlr3} framework, the model can be optimized to show an improved performance in a specific predictive setting [@schratz2019].
This may, for example, involve a reduced maximum tree depth in the Ecuador case study, since this leads to stronger generalization and reduced overfitting.


# Discussion {#sec:disc}

## Choosing a resampling method

The question which resampling method should be chosen for a prediction task and dataset at hand comes up regularly in practice.
Even though there is no definitive and easy answer, we would like to give some guidance in this section to help find an appropriate method.

Although the case study example in section \@ref(sec:case-study) used the `"spcv_coords"` method, this should not imply that this method is the best or only method suitable for this example task.
Even though this method is frequently used, it was mainly chosen because of its clear visual grouping differences when comparing spatial to random partitioning.
Another advantage is its ability to adapt to the irregularly shaped study area of this example.
Last, there are no obvious spatial groupings to our knowledge which need to be accounted for, also with respect to prediction purposes of the fitted model.

Most often multiple spatial partitioning methods can be used for a dataset.
It is recommended (required) to make oneself familiar with the available methods and to decide on one based on the specific characteristics of the dataset at hand and the prediction purpose of the fitted model.
The prediction purpose is the model's ability for which areas or zones it actually can make predictions.
In the crop example given in section \@ref(sec:intro) this would be to distinguish and predict the crop type of 'new', unseen fields within an agricultural region.
Hence, the CV partitioning is done at the field level to receive a honest estimate of the model's performance in a relevant predictive situation.

There are various factors that might influence the choice of a partitioning method:

- Do natural groupings exists in the data? Examples include multi-level sampling designs, land management units, or other characteristics of the study area or sampling design that may induce random effects.
- How dense are the observations scattered both in space and time?
  The closer observations are in space and/or time, the more similar they are, and hence the greater is the effect of spatio-temporal autocorrelation on performance estimates.
- Are some of the predictor variables under consideration known to be strongly autocorrelated such as air temperature or precipitation at the regional level?

Based on these criteria users should choose a matching partitioning method that is either more restrictive (by discarding observations for fold creation) or more liberal (by not removing observations and eventually ignoring natural grouping patterns).
For almost all methods implemented in \pkg{mlr3spatiotempcv}, there is a scientific publication describing the application areas of the respective approach (either linked in the help file of the package or its respective upstream packages), hence we are refraining from repeating them again in this study.

Last, a note on best practices for the example shown in section \@ref(sec:case-study):
In this example a cross-validation without hyperparameter tuning was applied.
In ML practice most often a nested CV should be desired to optimize model hyperparameter within the CV.
In such scenarios it is recommended to use the same spatial partitioning method for the inner loop (= tuning level) that was chosen for the outer one for consistency reasons.
See @schratz2019 for more details as well as chapter 11 of [Geocomputation with R](https://geocompr.robinlovelace.net/spatial-cv.html) [@lovelace2019].

## Comparing and discussing spatiotemporal resampling methods

Even though the prediction purpose should be the first decision criteria for choosing an appropriate spatiotemporal resampling method, we would like to discuss the individual methods in more detail in the following section.

<!-- high autocor on the border of test sets -->
<!-- sptcv LLTO: discards many observations -->
All methods which make use of all variables in the dataset suffer from the problem that on the border between train and test sets, both in the spatial and temporal domain, autocorrelation is relatively high (unless the dataset inherits natural groupings or gaps between train and test sets).
Methods that omit some observations (`"spcv_buffer"`, `"spcv_tiles"`, `"sptcv_cstf"` with both `space_var` and `time_var` set) are able to reduce the impact of autocorrelation in scenarios without a clear grouping or sufficient distance between train and test set observations.
The downside is the removal of observations from the dataset which possibly reduces the generalization power of the trained model and by this, depending on the specific observations that were removed, adds substantial bias to the CV results.

<!-- spcv_block: how to set argument `theRange` -->
<!-- AB: argument is actually called range, not theRange -->
Method `"spcv_block"` requires the user to supply a value for argument `range` which denotes the block size used to create the blocking scheme across the study area.
This specification is non-trivial and therefore package \pkg{blockCV} provides some helper functions (`spatialAutoRange()` and `rangeExplorer()`) to conduct a data-driven estimation of the distance at which the spatial autocorrelation in the data levels off [@blockCV].
According to the package authors, this estimate should then be used for argument `range` to have a sensible value for the block sizes created in method `"spcv_block"`.
Rectangular partitioning can be problematic in irregularly shaped study areas where some of the resulting partitions may contain substantially fewer observations than others.

<!-- sptcv LLO & LTO: requires additional variable to specify groupings -->
The `"spcv_cstf"` methods (with only one of `space_var` or `time_var` set) require a variable in the dataset which should be used for grouping.
The specification of such is not always easy because the grouping should ensure that the selected groups inherit substantial autocorrelation within themselves and simultaneously differ substantially from other groups.
Also, if the selected variable contains too many groups, the difference within train/test splits may become undesirably high and tend towards a LOO CV [@meyer2018].

<!-- only some methods are suited for repeated execution -->
<!-- spcv_coords: limited variance due to limited k-means possibilities -->
For repeated executions of method `spcv_coords`, the variance between repetitions can become quite small due to the limited possibilities of differing $k$-means-based clusters on the same dataset [@brenning2012].
This applies even more to `"spcv_block"` with options `selection = "systematic"` and `selection = "checkerboard"` as the fold assignments are the same in each repetition.
In general, only methods making use of a random component (e.g. `"spcv_coords"` or `"spcv_block"` with option `selection = "random"`) may be suited for using multiple repetitions.
On the upside, `"spcv_coords"` works well with irregularly shaped study areas due to its ability to create partitions which adjust well to the shape of the study area.

<!-- spcv buffer and spcv disc: discards observations, LOO very expensive -->
Methods `"spcv_buffer"` and `"spcv_disc"` (optionally) make use of the removal of observations to reduce the influence of spatial autocorrelation between train and test set.
This can be a pretty effective way to reduce autocorrelation but also requires to discard many observations.
In addition it comes with the downsides of a LOO-CV: many model fits which can be computationally very demanding and the results inheriting a high variance due to the high differences in the test sets (also commonly known as the "bias-variance tradeoff" [@wahba1998; @blockCV].
If a large buffer size is chosen relative to the size of the study area, a large portion of it will remain unsampled.
One should try to refrain from selecting a value based on subjective notions with respect to study area characteristics.

<!-- group level CV vs custom CV -->
\pkg{mlr3spatiotempcv} supports two factor-based partitioning schemes: "group-level resampling" and "custom resampling".
Both are similar in that they require external user input for partition creation, i.e. a factor variable which assigns all observations into a distinct group.
The idea of "custom resampling" is that each group becomes a test set in the CV (leave-one-group-out CV).
By contrast, "group-level resampling" methods resample these initial groups: for example, users can supply an integer value to an argument named `fold` in the LLO method (e.g. `5L`) which combines the initial groups (e.g. $n = 20$) into their final fold-level partitions, which would result in four groups per partition [@meyer2018].
The important point is that observations from within one group will either be assigned to the train or test set and never be split up.
"Group-level resampling" can be, in contrast to "custom resampling", repeated multiple times because multiple different aggregations are possible in theory.
However, it also requires the number of initial groups to be substantially higher than the number of folds so that a sensible aggregation is possible in the first place.

<!-- spcv coords: mention generic name -->
In @brenning2012, which is the reference commonly used for the $k$-means-based spatial partitioning approach, the method was not introduced with a unique name.
Over time, studies which have used this method mainly referenced it using the generic "spatial CV" terminology.
However, using this notation potentially introduces confusion as the term "spatial CV" is of a generic nature which refers to the idea of accounting for spatial autocorrelation in spatial datasets and does not necessarily refer to a specific partitioning method in the first place.
Hence, in package \pkg{mlr3spatiotempcv} this method was named `"spcv_coords"`, making use of the fact that the spatial coordinates are used for a cluster-based partition creation.


## Contributing new resampling methods

<!-- discuss pros and cons of implementing methods in a standalone pkg vs a framework -->
There are pros and cons on whether a new method should be integrated into an existing ecosystem such as \pkg{mlr3} directly or distributed in its own package.
When contributing a method to an existing ecosystem, developers can benefit from existing structures and orient themselves towards how previous methods were implemented.
They do not need to worry about complying with various R package related best practices (such as CRAN policies) and can solely focus on the method implementation.
Also, the new method will be directly usable by all people using this ecosystem following an existing and familiar syntax.
Contributions to (ML) ecosystems such as \pkg{mlr3} enables users to easily make use of a large variety of additional functionality, from preprocessing over hyperparameter tuning and feature selection to result visualization [@mlr3], which can be used in conjunction with the new resampling method.
In addition, contributions most likely undergo a thorough review from other community members during the implementation, most often enhancing the code quality of the implementation.
A direct contribution also reduces the maintenance load for the ecosystem developers as they do not need to wrap a new method into their system and watch for possible future changes.

On the contrary, people are forced to use the ecosystem and cannot easily use the method outside of it, whether its a different ecosystem or some other way.
They might also be forced to follow certain (coding) guidelines of the ecosystem and potentially feel constrained in their personal way of doing things.
Often, such ecosystems store their results in specialized classes, which make it hard for users to reuse them outside of the ecosystem.

# Conclusion and outlook

<!-- missing: Guidelines how to choose a resampling method -->
<!-- AB: I don't think we can present such guidelines in this paper, I think we discussed this recently and agreed that we will not propose such guidelines, we should rather focus on the methods and their implementation -->
The \pkg{mlr3spatiotempcv} package is the first package to bundle and categorize spatiotemporal resampling methods implemented in multiple other packages in R.
The available resampling techniques allow the users to vary the scale or granularity of the resampled spatial units as well as their shape and possible buffer distance between training and test samples.
These settings may account for the specific characteristics of spatiotemporal prediction tasks, but modelers now have to make the important decision of choosing a method that is adequate for their situation.
They are advised to focus on the spatial or spatiotemporal structure of the model's prediction task, consider the structure of the learning sample at hand, and think about how the autocorrelation between training and test samples might affect their model assessment and selection.

The compilation of resampling techniques in \pkg{mlr3spatiotempcv} is by no means complete.
Additional methods or parameters may therefore be added in the future as they become available in upstream package or are contributed directly to this package.

<!-- signoff -->
Spatiotemporal cross-validation a paradigm that is not yet fully established in scientific workflows although it has been discussed intensively for more than a decade now.
We anticipate that making the existing methods easily accessible to users is an important step to foster the acceptance of spatiotemporal cross-validation in the community and to allow modelers to produce less biased cross-validation results in environmental and ecological studies.

```{r echo=FALSE, cache=FALSE}
sessionInfo()
```

# References
